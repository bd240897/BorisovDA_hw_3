{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Машинное обучение.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bd240897/BorisovDA_hw_3/blob/master/%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bO5zEKCB5Rj"
      },
      "source": [
        "Олимпиада полу-финал\r\n",
        "\r\n",
        "что то интересное почитать \r\n",
        "https://alexanderdyakonov.files.wordpress.com/2015/04/ama2015_scikit.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoZZf-TTr1PK"
      },
      "source": [
        "Порядок заливаемых ответов 02.03.21:\r\n",
        "\r\n",
        "Номер,   Время,   Тип модели\r\n",
        "---\r\n",
        "1. 19-19, АдаБуст без всего, 0.57 - ОШИБКА\r\n",
        "---\r\n",
        "2. 19-29, Тоже самое что и 1 (49073561)\r\n",
        "---\r\n",
        "3. 20-13, Тоже самое что и 2 только без стоблцов (49075804)\r\n",
        "---\r\n",
        "4. 20-20, Случайный лес, чистый (49076104)\r\n",
        "---\r\n",
        "5. 21-47, Голосование 3х алгоримтмов, неправильное обучение на выборке (49080202)\r\n",
        "---\r\n",
        "6. 21-48, Голосование 3х алгоритмов вытащил алгоритмы а потмо обучил (49080215)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMR5WOkCMBpH"
      },
      "source": [
        "## Импорт библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eEFRs2bLjYW"
      },
      "source": [
        "import csv\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, median_absolute_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAeDcBWKvdE_"
      },
      "source": [
        "ИДЕИ\n",
        "\n",
        "1) импортируем данные \n",
        "2) Обработаем данные\n",
        "- отмасштабирем y*100 для более видной MSE\n",
        "*будем использоват MSE а не RMSE так как она нагляднее и по сути это одно и тоже\n",
        "3) Иследуем данные\n",
        "3.1. Количество уникальных значений\n",
        "3.2. 3д график данных \n",
        "3.3. Гитаграмма\n",
        "3.4. Проверка закономерностей вдоль осей Х и оси У\n",
        "\n",
        "4) Попробуем методы в ЛОБ\n",
        "4.1. Логическая регрессия\n",
        "4.2. Ридж регрессия\n",
        "4.3. Лассо регресия\n",
        "4.4. Эластик нет\n",
        "4.5. Полиномиальная регрессия \n",
        "\n",
        "5) Действия усложненные\n",
        "5.1. Сведем задачу к классификации \n",
        "5.1.1. Разделим на 6 классов \n",
        "5.1.1.1. # Многоклассовая One-Vs-Rest - с GradBust\n",
        "5.1.1.2. # Многоклассовая One-Vs-One - с GradBust\n",
        "5.1.1.3. # Многоклассовая One-Vs-Rest - SVM - работает оч долго, поэтому писал свой\n",
        "5.1.2. Разделим на 12 классов \n",
        "\n",
        "5.2. Попробуем самостоятельно придумать коэфиценты для полинома\n",
        "\n",
        "5.3. KNN - запоминаниие выборки \n",
        "\n",
        "5.4 Попробуем кластаризация для разбивки по значениям в потом уже \"полином регрессию\"\n",
        "ПОПРОБОВАТЬ ЭТО!\n",
        "\n",
        "5.5. Задавать константный алгоритм который возвращает среднее по оси Y за обучающую выборку \n",
        "* а если такого нет, то среднюю между соседними линиями \n",
        "5.6. Вложенные лагоритмы + голосование\n",
        "Идея: первй алгоритм определяет линии по У -> номер линии т.е. список по X\n",
        "Далее по номеру линии 2м класификатором для каждой входной точки определим ниболее вероятную глубину по х\n",
        "Обучение:\n",
        "ИДЕЯ: ищем линию наиболее похожую на эту точку.\n",
        "Если в обучающей Х 0 точек -> такого варианта не должно\n",
        "Если по Х одна точка - то вернем ее\n",
        "Если по Х две точки - то вернем ту к которой ближе Х входной точки\n",
        "Если по Х много точек то заготовим классификатор который по X можем определить значения песчаности \n",
        "Т.Е, ВЫБИРЕМ НОМЕР ЛИНИИ Y а затем интарпалирем Х - в случае 2х тоек это прямая  \n",
        "6) получим результат для ответа"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAVbjYZJvdFB"
      },
      "source": [
        "### 1. Импортируем данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "SIGwyVMpvdFB",
        "outputId": "47bed659-3ae5-4577-f3de-2b9c98de1455"
      },
      "source": [
        "# тренеровочный датасет\n",
        "df_train = pd.read_csv(\"Training_wells.csv\")\n",
        "df_train.head(3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Well</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>NTG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>201-907</td>\n",
              "      <td>201</td>\n",
              "      <td>907</td>\n",
              "      <td>0.2006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>201-914</td>\n",
              "      <td>201</td>\n",
              "      <td>914</td>\n",
              "      <td>0.3624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>201-924</td>\n",
              "      <td>201</td>\n",
              "      <td>924</td>\n",
              "      <td>0.4381</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Well    X    Y     NTG\n",
              "0  201-907  201  907  0.2006\n",
              "1  201-914  201  914  0.3624\n",
              "2  201-924  201  924  0.4381"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "bbtFW9FYvdFE",
        "outputId": "44c5676b-13e4-4de4-d5a4-ba4bb556041c"
      },
      "source": [
        "# добавим индекс как столбец\n",
        "df_train['index'] = df_train.index\n",
        "df_train.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Well</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>NTG</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>201-907</td>\n",
              "      <td>201</td>\n",
              "      <td>907</td>\n",
              "      <td>0.2006</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>201-914</td>\n",
              "      <td>201</td>\n",
              "      <td>914</td>\n",
              "      <td>0.3624</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>201-924</td>\n",
              "      <td>201</td>\n",
              "      <td>924</td>\n",
              "      <td>0.4381</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Well    X    Y     NTG  index\n",
              "0  201-907  201  907  0.2006      0\n",
              "1  201-914  201  914  0.3624      1\n",
              "2  201-924  201  924  0.4381      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjOlVnqjvdFF"
      },
      "source": [
        "# well - номер скважины (координаты х и у)\n",
        "# X - дублирует ВЕЛЛ\n",
        "# Y - дублирует ВЕЛЛ\n",
        "# критерий оценки RMSE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "ei1Y8SjdvdFG",
        "outputId": "ace263eb-f841-4eda-829b-9ebe08d77e18"
      },
      "source": [
        "# рабочий датасет\n",
        "df_work = pd.read_csv(\"Empty_part.csv\")\n",
        "df_work.head(3)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Well</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>201-901</td>\n",
              "      <td>201</td>\n",
              "      <td>901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>201-902</td>\n",
              "      <td>201</td>\n",
              "      <td>902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>201-903</td>\n",
              "      <td>201</td>\n",
              "      <td>903</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Well    X    Y\n",
              "0  201-901  201  901\n",
              "1  201-902  201  902\n",
              "2  201-903  201  903"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "fpEBPJ6evdFH",
        "outputId": "0f3dcfe6-6039-4a9d-beb3-6b446b82968d"
      },
      "source": [
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Well</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>NTG</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>201-907</td>\n",
              "      <td>201</td>\n",
              "      <td>907</td>\n",
              "      <td>0.2006</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>201-914</td>\n",
              "      <td>201</td>\n",
              "      <td>914</td>\n",
              "      <td>0.3624</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>201-924</td>\n",
              "      <td>201</td>\n",
              "      <td>924</td>\n",
              "      <td>0.4381</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>202-922</td>\n",
              "      <td>202</td>\n",
              "      <td>922</td>\n",
              "      <td>0.4289</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>202-925</td>\n",
              "      <td>202</td>\n",
              "      <td>925</td>\n",
              "      <td>0.4021</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>245-908</td>\n",
              "      <td>245</td>\n",
              "      <td>908</td>\n",
              "      <td>0.2719</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>245-911</td>\n",
              "      <td>245</td>\n",
              "      <td>911</td>\n",
              "      <td>0.3780</td>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>245-923</td>\n",
              "      <td>245</td>\n",
              "      <td>923</td>\n",
              "      <td>0.4239</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>246-905</td>\n",
              "      <td>246</td>\n",
              "      <td>905</td>\n",
              "      <td>0.4900</td>\n",
              "      <td>136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>246-923</td>\n",
              "      <td>246</td>\n",
              "      <td>923</td>\n",
              "      <td>0.3667</td>\n",
              "      <td>137</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>138 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Well    X    Y     NTG  index\n",
              "0    201-907  201  907  0.2006      0\n",
              "1    201-914  201  914  0.3624      1\n",
              "2    201-924  201  924  0.4381      2\n",
              "3    202-922  202  922  0.4289      3\n",
              "4    202-925  202  925  0.4021      4\n",
              "..       ...  ...  ...     ...    ...\n",
              "133  245-908  245  908  0.2719    133\n",
              "134  245-911  245  911  0.3780    134\n",
              "135  245-923  245  923  0.4239    135\n",
              "136  246-905  246  905  0.4900    136\n",
              "137  246-923  246  923  0.3667    137\n",
              "\n",
              "[138 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV_WhLlivdFI"
      },
      "source": [
        "# разделим на выборку и тест \n",
        "x_train = df_train[['X','Y']]\n",
        "y_train = df_train['Y']\n",
        "# y_train.size\n",
        "# x_train.count()\n",
        "# 138 строки всего???"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxZKDpwEvdFJ"
      },
      "source": [
        "### Исследуем входные данные "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "YmmrpjDKvdFK",
        "outputId": "ba046559-c3c0-4a7a-a10f-8786a6916f2b"
      },
      "source": [
        "pd.DataFrame(df_train['X'].value_counts()).head(3)\n",
        "pd.DataFrame(df_train['Y'].value_counts()).head(3)\n",
        "pd.DataFrame(df_train['NTG'].value_counts()).head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NTG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.2778</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.2766</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.3333</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        NTG\n",
              "0.2778    2\n",
              "0.2766    2\n",
              "0.3333    2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8tEusCuvdFK"
      },
      "source": [
        "# Построим гистаграмму \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "JxEnuOOGvdFL",
        "scrolled": true,
        "outputId": "3ef441f2-39bf-4c36-ffda-d5a2cb09c265"
      },
      "source": [
        "# построим 3д график\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "from scipy.interpolate import griddata\n",
        "\n",
        "x = df_train['X'].to_list()\n",
        "y = df_train['Y'].to_list()\n",
        "z = df_train['NTG'].to_list()\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "z = np.array(z)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(231, projection='3d')\n",
        "ax.plot(x, y, z, label='parametric curve')\n",
        "\n",
        "ax = fig.add_subplot(232, projection='3d')\n",
        "ax.scatter(x, y, z)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fe213d0efd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwn9XJJYvdFr"
      },
      "source": [
        "### Поищем закономерности в данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ9F0Uc3vdFr",
        "outputId": "0696848a-acba-4fdc-b51d-04f7fff0cbb3"
      },
      "source": [
        "# посмотри как изменяется уровень по оси X\n",
        "\n",
        "dict_for_X = dict()\n",
        "for x in set(df_train['X'].to_list()):\n",
        "    y = df_train[df_train['X'] == x]['NTG'].to_list()\n",
        "    \n",
        "    if dict_for_X.pop(x, -1) == -1:\n",
        "        dict_for_X[x] = y\n",
        "    else:\n",
        "        dict_for_X[x].append(y)\n",
        "        \n",
        "dict_for_X\n",
        "# ВЫВОД: по Х зависимости НЕТ"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{201: [0.2006, 0.3624, 0.4381],\n",
              " 202: [0.4289, 0.4021],\n",
              " 203: [0.2628, 0.2517, 0.3452],\n",
              " 204: [0.2092, 0.1974, 0.4136],\n",
              " 205: [0.3061, 0.3268, 0.3431, 0.3568],\n",
              " 206: [0.3054, 0.3228, 0.2682],\n",
              " 207: [0.1897, 0.3249, 0.2659, 0.3205, 0.2963, 0.2637],\n",
              " 208: [0.3971, 0.2775, 0.3244],\n",
              " 209: [0.3729],\n",
              " 210: [0.3801, 0.4419, 0.3869],\n",
              " 211: [0.4042, 0.3901, 0.3333, 0.3661, 0.3533],\n",
              " 212: [0.3394, 0.2251, 0.3388],\n",
              " 214: [0.3769, 0.3484],\n",
              " 215: [0.3125, 0.3867, 0.3402, 0.25, 0.3512, 0.2918],\n",
              " 216: [0.3248, 0.2419, 0.3791, 0.4099, 0.2759],\n",
              " 217: [0.2979, 0.2762],\n",
              " 218: [0.4562, 0.2865, 0.3721],\n",
              " 219: [0.4488, 0.4436, 0.3375, 0.2514, 0.2895, 0.2287, 0.3941],\n",
              " 220: [0.2484],\n",
              " 221: [0.4369, 0.4],\n",
              " 222: [0.3857, 0.3557],\n",
              " 223: [0.3894, 0.2795],\n",
              " 224: [0.3162, 0.3775],\n",
              " 225: [0.3471, 0.3081, 0.2386, 0.2794, 0.2961],\n",
              " 226: [0.2778, 0.3299, 0.3322, 0.429],\n",
              " 227: [0.3636, 0.2778],\n",
              " 228: [0.4268, 0.325, 0.4079],\n",
              " 229: [0.3421, 0.3774, 0.3764],\n",
              " 230: [0.2562, 0.3074],\n",
              " 231: [0.3486, 0.3201, 0.3018],\n",
              " 232: [0.2519, 0.2766, 0.3579, 0.2674],\n",
              " 234: [0.2347],\n",
              " 235: [0.5625, 0.2874, 0.2696],\n",
              " 237: [0.4356, 0.2244, 0.2381, 0.2653, 0.2851],\n",
              " 238: [0.3534, 0.2312, 0.2454],\n",
              " 239: [0.3882, 0.2137, 0.2189],\n",
              " 240: [0.3973, 0.2909, 0.3391],\n",
              " 241: [0.3333, 0.2171, 0.2766, 0.2371],\n",
              " 242: [0.5, 0.177, 0.355],\n",
              " 243: [0.1786, 0.2816, 0.3981],\n",
              " 244: [0.3566, 0.2463, 0.2543, 0.2584, 0.3670000000000001, 0.3835],\n",
              " 245: [0.2719, 0.378, 0.4239],\n",
              " 246: [0.49, 0.3667]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVdQ7GR_vdFs",
        "outputId": "41b1a911-fad0-44ab-9c62-b3334ffca25f"
      },
      "source": [
        "# посмотри как изменяется уровень по оси X\n",
        "\n",
        "dict_for_Y = dict()\n",
        "for y in set(df_train['Y'].to_list()):\n",
        "    x = df_train[df_train['Y'] == y]['NTG'].to_list()\n",
        "    \n",
        "    if dict_for_Y.pop(y, -1) == -1:\n",
        "        dict_for_Y[y] = x\n",
        "    else:\n",
        "        dict_for_Y[y].append(x)\n",
        "        \n",
        "dict_for_Y\n",
        "# ВЫВОД: по Y есть какая то слабая зависимость "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{901: [0.4369, 0.4268, 0.3882],\n",
              " 902: [0.2628, 0.3248, 0.4488, 0.4, 0.3636],\n",
              " 903: [0.4436, 0.5625, 0.5],\n",
              " 904: [0.2092, 0.3394, 0.3769, 0.4356],\n",
              " 905: [0.2251, 0.4562, 0.3894, 0.49],\n",
              " 906: [0.2517],\n",
              " 907: [0.2006, 0.1974, 0.1897, 0.3375, 0.3162, 0.3534, 0.3333, 0.177, 0.1786],\n",
              " 908: [0.2419, 0.3471, 0.325, 0.2562, 0.2719],\n",
              " 909: [0.2514, 0.2778, 0.2778],\n",
              " 910: [0.3249, 0.3125, 0.2519, 0.2137, 0.2171],\n",
              " 911: [0.3061, 0.2766, 0.3566, 0.378],\n",
              " 912: [0.3054, 0.2659, 0.4079, 0.2463],\n",
              " 913: [0.3867, 0.2895, 0.3973],\n",
              " 914: [0.3624, 0.3228, 0.3801, 0.4042, 0.2244],\n",
              " 915: [0.3971, 0.3857, 0.3775, 0.2874],\n",
              " 916: [0.3268, 0.3729, 0.4419, 0.3402, 0.3081],\n",
              " 917: [0.3791, 0.3557, 0.3579],\n",
              " 918: [0.3484, 0.355],\n",
              " 919: [0.3205, 0.2775, 0.3901, 0.2381],\n",
              " 920: [0.4099, 0.3421, 0.3486, 0.2653, 0.2543],\n",
              " 921: [0.3388, 0.25, 0.2386, 0.3074, 0.2347, 0.2312, 0.2766, 0.2584],\n",
              " 922: [0.4289, 0.2979, 0.2794, 0.2189, 0.2371],\n",
              " 923: [0.3431, 0.3869, 0.2484, 0.3670000000000001, 0.4239, 0.3667],\n",
              " 924: [0.4381, 0.3333, 0.2287, 0.2696, 0.2851, 0.2454],\n",
              " 925: [0.4021, 0.4136, 0.3244, 0.3774],\n",
              " 926: [0.2762, 0.3299, 0.3764, 0.2909, 0.2816],\n",
              " 927: [0.3568, 0.2963, 0.3661, 0.2759, 0.3835],\n",
              " 928: [0.3533, 0.3512, 0.2961, 0.3322, 0.3391, 0.3981],\n",
              " 929: [0.3452, 0.2682, 0.2865, 0.429, 0.3201, 0.2674],\n",
              " 930: [0.2637, 0.2918, 0.3721, 0.3941, 0.2795, 0.3018]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvfN_SV4vdFs",
        "outputId": "286ce920-fb69-4530-df00-8226cc6348b6"
      },
      "source": [
        "df_train[(df_train['NTG'] < 0.4) & (df_train['NTG'] > 0.2)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Well</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>NTG</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>201-907</td>\n",
              "      <td>201</td>\n",
              "      <td>907</td>\n",
              "      <td>0.2006</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>201-914</td>\n",
              "      <td>201</td>\n",
              "      <td>914</td>\n",
              "      <td>0.3624</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>203-902</td>\n",
              "      <td>203</td>\n",
              "      <td>902</td>\n",
              "      <td>0.2628</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>203-906</td>\n",
              "      <td>203</td>\n",
              "      <td>906</td>\n",
              "      <td>0.2517</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>203-929</td>\n",
              "      <td>203</td>\n",
              "      <td>929</td>\n",
              "      <td>0.3452</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>244-923</td>\n",
              "      <td>244</td>\n",
              "      <td>923</td>\n",
              "      <td>0.3670</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>244-927</td>\n",
              "      <td>244</td>\n",
              "      <td>927</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>245-908</td>\n",
              "      <td>245</td>\n",
              "      <td>908</td>\n",
              "      <td>0.2719</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>245-911</td>\n",
              "      <td>245</td>\n",
              "      <td>911</td>\n",
              "      <td>0.3780</td>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>246-923</td>\n",
              "      <td>246</td>\n",
              "      <td>923</td>\n",
              "      <td>0.3667</td>\n",
              "      <td>137</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Well    X    Y     NTG  index\n",
              "0    201-907  201  907  0.2006      0\n",
              "1    201-914  201  914  0.3624      1\n",
              "5    203-902  203  902  0.2628      5\n",
              "6    203-906  203  906  0.2517      6\n",
              "7    203-929  203  929  0.3452      7\n",
              "..       ...  ...  ...     ...    ...\n",
              "131  244-923  244  923  0.3670    131\n",
              "132  244-927  244  927  0.3835    132\n",
              "133  245-908  245  908  0.2719    133\n",
              "134  245-911  245  911  0.3780    134\n",
              "137  246-923  246  923  0.3667    137\n",
              "\n",
              "[114 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VzqFTgYvdFt",
        "outputId": "80238dab-aefe-49b4-e936-2dcd036ff38c"
      },
      "source": [
        "dict_for_X = dict({1:1})\n",
        "dict_for_X\n",
        "df_train[df_train['X'] == 201]['NTG'].to_list()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2006, 0.3624, 0.4381]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "wwxhTr73SoSX",
        "outputId": "ac697b70-bcdb-4588-8df6-bb2f52969a75"
      },
      "source": [
        "# построим гистограмму входных данных\r\n",
        "import numpy as np\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "df_train['X'].hist(bins=14)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe21c4a8e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBSJLcN9vdFt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "ea0696dc-8e90-4502-ff7f-6f5c1dde045c"
      },
      "source": [
        "df_train['Y'].hist(bins=14)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe21c3ef1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "barYAi9oSxV1",
        "outputId": "f2eb7f50-a1a6-49d1-cf90-57a8950a72a4"
      },
      "source": [
        "df_train['NTG'].hist(bins=14)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe21be4ae90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUkR2XIFlUoc"
      },
      "source": [
        "### Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8ZH7bPJvdFP"
      },
      "source": [
        "# разделим выборку на тест и обучение \n",
        "\n",
        "x_train = df_train[['X','Y']]\n",
        "y_train = df_train['NTG']\n",
        "x_train_split, x_test_split, y_train_split, y_test_split = train_test_split(x_train, y_train, test_size=0.33, random_state=42)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AqI08YCvdFP"
      },
      "source": [
        "# для читабельности оценок умножим y на 100 \n",
        "# def multiply_y_100():\n",
        "# \"\"\"для читабельности оценок обучение умножим \"y\" на 100\"\"\"\n",
        "# y_train_split = y_train_split*100\n",
        "# y_test_split = y_test_split*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmmAnxh7vdFQ"
      },
      "source": [
        "# Сравним несколько простых моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJRR30BBh98-"
      },
      "source": [
        "### Попробуем разные обработки входных данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQREv6JciszJ"
      },
      "source": [
        "Power Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DImTEaliFCW"
      },
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer\n",
        "\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "pt = PowerTransformer()\n",
        "\n",
        "x_train_split = pt.fit_transform(x_train_split)\n",
        "x_test_split = pt.transform(x_test_split)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IarSy7criv8J"
      },
      "source": [
        "MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFc9dtWpi_5x"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0.0, 1.0))\n",
        "\n",
        "x_train_split = scaler.fit_transform(x_train_split)\n",
        "x_test_split = scaler.transform(x_test_split)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmf0B1asnOln"
      },
      "source": [
        "RobustScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29ZQGJLQnQqB"
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler\n",
        "\n",
        "transformer = RobustScaler()\n",
        "\n",
        "x_train_split = transformer.fit_transform(x_train_split)\n",
        "x_test_split = transformer.transform(x_test_split)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_s5m-PRnkmk"
      },
      "source": [
        "StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEMSYj1pnmIx"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler\n",
        "\n",
        "transformer = StandardScaler()\n",
        "\n",
        "x_train_split = transformer.fit_transform(x_train_split)\n",
        "x_test_split = transformer.transform(x_test_split)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzvU5aX5n9VI"
      },
      "source": [
        "PolynomialFeatures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJKJzW03nkFT"
      },
      "source": [
        "poly_reg = PolynomialFeatures(degree=5)\n",
        "x_train_split  = poly_reg.fit_transform(x_train_split)\n",
        "x_test_split = poly_reg.fit_transform(x_test_split)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTNGsymivdFQ"
      },
      "source": [
        "### LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0EcuKejvdFR",
        "outputId": "afadf9d1-5215-4774-e13b-a55a815062a3"
      },
      "source": [
        "# обучим линейную регрессию\n",
        "def line_regresion():\n",
        "  \"\"\"обучим линейную регрессию\"\"\"\n",
        "  est_acc = LinearRegression()\n",
        "  est_acc.fit(x_train_split, y_train_split)\n",
        "  y_train_pred = est_acc.predict(x_train_split)\n",
        "  y_test_pred = est_acc.predict(x_test_split)\n",
        "\n",
        "  # вывод оценок обучения\n",
        "  print('MSE train: {:.3f}, test: {:.3f}'.format(\n",
        "          mean_squared_error(y_train_split, y_train_pred),\n",
        "          mean_squared_error(y_test_split, y_test_pred)))\n",
        "  print('R^2 train: {:.3f}, test: {:.3f}'.format(\n",
        "          r2_score(y_train_split, y_train_pred),\n",
        "          r2_score(y_test_split, y_test_pred)))\n",
        "  print('RMSE train: {:.3f}, test: {:.3f}'.format(\n",
        "          math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\n",
        "          math.sqrt(mean_squared_error(y_test_split, y_test_pred))))\n",
        "  \n",
        "line_regresion()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE train: 0.003, test: 0.005\n",
            "R^2 train: 0.516, test: -0.110\n",
            "RMSE train: 0.052, test: 0.072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5vi5vVqvdFS"
      },
      "source": [
        "# разница которую можно увидеть\n",
        "# np.array(y_train_split.to_list())-y_train_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqJd7fqpqHNw"
      },
      "source": [
        "### OrthogonalMatchingPursuit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDA3z2icqGHh",
        "outputId": "d010607c-1f78-4dea-b79a-2d6f9c104247"
      },
      "source": [
        "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
        "\n",
        "omp = OrthogonalMatchingPursuit(n_nonzero_coefs=2)\n",
        "omp.fit(x_train_split, y_train_split)\n",
        "\n",
        "y_train_pred = omp.predict(x_train_split)\n",
        "y_test_pred = omp.predict(x_test_split)\n",
        "\n",
        "# вывод оценок обучения\n",
        "print('MSE train: {:.3f}, test: {:.3f}'.format(\n",
        "        mean_squared_error(y_train_split, y_train_pred),\n",
        "        mean_squared_error(y_test_split, y_test_pred)))\n",
        "print('R^2 train: {:.3f}, test: {:.3f}'.format(\n",
        "        r2_score(y_train_split, y_train_pred),\n",
        "        r2_score(y_test_split, y_test_pred)))\n",
        "print('RMSE train: {:.3f}, test: {:.3f}'.format(\n",
        "        math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\n",
        "        math.sqrt(mean_squared_error(y_test_split, y_test_pred))))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE train: 0.005, test: 0.005\n",
            "R^2 train: 0.020, test: -0.020\n",
            "RMSE train: 0.073, test: 0.069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCogqvErrj1H"
      },
      "source": [
        "### SGDRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYPgy_CarA_N",
        "outputId": "8c466d26-6fc1-4fd6-dc68-79957616895b"
      },
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "rng = np.random.RandomState(0)\n",
        "y = y_train_split\n",
        "X = x_train_split\n",
        "\n",
        "reg = make_pipeline(StandardScaler(),\n",
        "                   SGDRegressor(max_iter=1000, tol=1e-3))\n",
        "reg.fit(X, y)\n",
        "y_train_pred = reg.predict(x_train_split)\n",
        "y_test_pred = reg.predict(x_test_split)\n",
        "\n",
        "# вывод оценок обучения\n",
        "print('MSE train: {:.3f}, test: {:.3f}'.format(\n",
        "        mean_squared_error(y_train_split, y_train_pred),\n",
        "        mean_squared_error(y_test_split, y_test_pred)))\n",
        "print('R^2 train: {:.3f}, test: {:.3f}'.format(\n",
        "        r2_score(y_train_split, y_train_pred),\n",
        "        r2_score(y_test_split, y_test_pred)))\n",
        "print('RMSE train: {:.3f}, test: {:.3f}'.format(\n",
        "        math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\n",
        "        math.sqrt(mean_squared_error(y_test_split, y_test_pred))))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE train: 0.006, test: 0.006\n",
            "R^2 train: -0.136, test: -0.258\n",
            "RMSE train: 0.079, test: 0.076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK5TJlyfyuTD"
      },
      "source": [
        "### BayesianRidge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm6wc0JLsv0I",
        "outputId": "995d670e-3f86-43b5-9fee-ed4f29823573"
      },
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "y = y_train_split\n",
        "X = x_train_split\n",
        "\n",
        "clf = linear_model.BayesianRidge()\n",
        "clf.fit(X, y)\n",
        "y_train_pred = clf.predict(x_train_split)\n",
        "y_test_pred = clf.predict(x_test_split)\n",
        "\n",
        "# вывод оценок обучения\n",
        "print('MSE train: {:.3f}, test: {:.3f}'.format(\n",
        "        mean_squared_error(y_train_split, y_train_pred),\n",
        "        mean_squared_error(y_test_split, y_test_pred)))\n",
        "print('R^2 train: {:.3f}, test: {:.3f}'.format(\n",
        "        r2_score(y_train_split, y_train_pred),\n",
        "        r2_score(y_test_split, y_test_pred)))\n",
        "print('RMSE train: {:.3f}, test: {:.3f}'.format(\n",
        "        math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\n",
        "        math.sqrt(mean_squared_error(y_test_split, y_test_pred))))\n",
        "\n",
        "clf = linear_model.ARDRegression()\n",
        "clf.fit(X, y)\n",
        "y_train_pred = clf.predict(x_train_split)\n",
        "y_test_pred = clf.predict(x_test_split)\n",
        "\n",
        "# вывод оценок обучения\n",
        "print('MSE train: {:.3f}, test: {:.3f}'.format(\n",
        "        mean_squared_error(y_train_split, y_train_pred),\n",
        "        mean_squared_error(y_test_split, y_test_pred)))\n",
        "print('R^2 train: {:.3f}, test: {:.3f}'.format(\n",
        "        r2_score(y_train_split, y_train_pred),\n",
        "        r2_score(y_test_split, y_test_pred)))\n",
        "print('RMSE train: {:.3f}, test: {:.3f}'.format(\n",
        "        math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\n",
        "        math.sqrt(mean_squared_error(y_test_split, y_test_pred))))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE train: 0.005, test: 0.005\n",
            "R^2 train: 0.014, test: -0.011\n",
            "RMSE train: 0.074, test: 0.068\n",
            "MSE train: 0.005, test: 0.005\n",
            "R^2 train: 0.000, test: -0.007\n",
            "RMSE train: 0.074, test: 0.068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tCkcBRXjkZ_"
      },
      "source": [
        "### AdaBoostRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "fIe8ubOPTPLr",
        "outputId": "b7956e8b-287e-4d6e-9a68-b83b56881d1a"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\r\n",
        "\r\n",
        "regr = AdaBoostRegressor(base_estimator=None, learning_rate=1.6273721018635237,\r\n",
        "                  loss='linear', n_estimators=35, random_state=2100)\r\n",
        "regr.fit(x_train_split, y_train_split)\r\n",
        "\r\n",
        "y_train_pred = regr.predict(x_train_split)\r\n",
        "y_test_pred = regr.predict(x_test_split)\r\n",
        "\r\n",
        "print('MAE train: {:.3f}, test: {:.3f}'.format(\r\n",
        "        mean_absolute_error(y_train_split, y_train_pred),\r\n",
        "        mean_absolute_error(y_test_split, y_test_pred)))\r\n",
        "print('MSE train: {:.3f}, test: {:.3f}'.format(\r\n",
        "        mean_squared_error(y_train_split, y_train_pred),\r\n",
        "        mean_squared_error(y_test_split, y_test_pred)))\r\n",
        "print('R^2 train: {:.3f}, test: {:.3f}'.format(\r\n",
        "        r2_score(y_train_split, y_train_pred),\r\n",
        "        r2_score(y_test_split, y_test_pred)))\r\n",
        "print('RMSE train: {:.3f}, test: {:.3f}'.format(\r\n",
        "        math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\r\n",
        "        math.sqrt(mean_squared_error(y_test_split, y_test_pred))))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-72-2088ec950b62>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    print('MAE train: {:.3f}, test: {:.3f}'.format(\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HuUhQ-kTcJI"
      },
      "source": [
        "### Голосование алгоритмо"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5wCsW7xTm-_"
      },
      "source": [
        "# голосование версия - 1 - два алгоритма"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYEhNb8ajrO2",
        "outputId": "7573b8b9-0b7a-48f3-b0a7-1bdb63f1bc96"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from hpsklearn import ada_boost_regression\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from hpsklearn import HyperoptEstimator\n",
        "from hpsklearn import any_regressor\n",
        "from hpsklearn import any_preprocessing\n",
        "from hyperopt import tpe\n",
        "from hpsklearn import HyperoptEstimator, xgboost_regression, random_forest_regression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# разделим выборку на тест и обучение \n",
        "score = []\n",
        "\n",
        "for i in range(5,6):\n",
        "  x_train = df_train[['X','Y']]\n",
        "  y_train = df_train['NTG']\n",
        "  x_train_split, x_test_split, y_train_split, y_test_split = train_test_split(x_train, y_train, test_size=0.33, random_state=42)\n",
        "\n",
        "  poly_reg = PolynomialFeatures(degree=i)\n",
        "  x_train_split  = poly_reg.fit_transform(x_train_split)\n",
        "  x_test_split = poly_reg.fit_transform(x_test_split)\n",
        "\n",
        "  scaler = MinMaxScaler(feature_range=(0.0, 1.0))\n",
        "  x_train_split = scaler.fit_transform(x_train_split)\n",
        "  x_test_split = scaler.transform(x_test_split)\n",
        "\n",
        "  regr = AdaBoostRegressor(base_estimator=None, learning_rate=1.6273721018635237,\n",
        "                    loss='linear', n_estimators=35, random_state=2100)\n",
        "  regr.fit(x_train_split, y_train_split)\n",
        "\n",
        "  y_train_pred = regr.predict(x_train_split)\n",
        "  y_test_pred = regr.predict(x_test_split)\n",
        "\n",
        "  ################################3\n",
        "  model = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
        "                        max_depth=20, max_features='sqrt', max_leaf_nodes=None,\n",
        "                        max_samples=None, min_impurity_decrease=0.0,\n",
        "                        min_impurity_split=None, min_samples_leaf=2,\n",
        "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "                        n_estimators=250, n_jobs=None, oob_score=False,\n",
        "                        random_state=30, verbose=0, warm_start=False)\n",
        "\n",
        "  model.fit(x_train_split, y_train_split)\n",
        "  y_train_pred_2 = model.predict(x_train_split)\n",
        "  y_test_pred_2 = model.predict(x_test_split)\n",
        "\n",
        "  al = 0.5\n",
        "  # y_train_pred = (al*y_train_pred + (1-al)*y_train_pred_2)\n",
        "  # y_test_pred = (al*y_test_pred + (1-al)*y_test_pred_2)\n",
        "  ###################################\n",
        "  estim = HyperoptEstimator(regressor=ada_boost_regression('my_gb'),\n",
        "                          max_evals=10, trial_timeout=10, seed=39,\n",
        "                          loss_fn=mean_squared_error)\n",
        "\n",
        "  estim.fit(x_train_split, y_train_split)\n",
        "  y_train_pred_3 = estim.predict(x_train_split)\n",
        "  y_test_pred_3 = estim.predict(x_test_split)\n",
        "\n",
        "\n",
        "  A = 0.5\n",
        "  B = 0.25\n",
        "  C = 1 - A - B\n",
        "  y_train_pred = A*y_train_pred + + B*y_train_pred_2 + C*y_train_pred_3\n",
        "  y_test_pred = A*y_test_pred + B*y_test_pred_2 + C*y_test_pred_3\n",
        "\n",
        "\n",
        "  print('MAE train: {:.3f}, test: {:.3f}'.format(\n",
        "          mean_absolute_error(y_train_split, y_train_pred),\n",
        "          mean_absolute_error(y_test_split, y_test_pred)))\n",
        "  print('MSE train: {:.3f}, test: {:.3f}'.format(\n",
        "          mean_squared_error(y_train_split, y_train_pred),\n",
        "          mean_squared_error(y_test_split, y_test_pred)))\n",
        "  print('R^2 train: {:.3f}, test: {:.3f}'.format(\n",
        "          r2_score(y_train_split, y_train_pred),\n",
        "          r2_score(y_test_split, y_test_pred)))\n",
        "  print('RMSE train: {:.3f}, test: {:.3f}'.format(\n",
        "          math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\n",
        "          math.sqrt(mean_squared_error(y_test_split, y_test_pred))))\n",
        "  print('Cтепень равняется ', i)\n",
        "  print('######################################')  \n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  5.58it/s, best loss: 0.004042153039546323]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.34it/s, best loss: 0.004042153039546323]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.35s/it, best loss: 0.0030080621865901163]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.10it/s, best loss: 0.00267824472350862]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.18it/s, best loss: 0.00267824472350862]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.27it/s, best loss: 0.00267824472350862]\n",
            "100%|██████████| 1/1 [00:00<00:00, 13.55it/s, best loss: 0.00267824472350862]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.25it/s, best loss: 0.00267824472350862]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.62it/s, best loss: 0.00267824472350862]\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.45it/s, best loss: 0.00267824472350862]\n",
            "MAE train: 0.032, test: 0.049\n",
            "MSE train: 0.001, test: 0.003\n",
            "R^2 train: 0.742, test: 0.309\n",
            "RMSE train: 0.038, test: 0.056\n",
            "Cтепень равняется  5\n",
            "######################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Pv5LldkFPs6"
      },
      "source": [
        "\r\n",
        "\r\n",
        "Голосование алгоритмов версия 2\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sme4dyLgFL0N"
      },
      "source": [
        "# Голосование алгоритмов версия 2 - три алгоритма"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSr1WFpoD0HM",
        "outputId": "0d441dde-e6bc-4177-a552-6f00a2da9a6f"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\r\n",
        "from sklearn.datasets import make_regression\r\n",
        "from hpsklearn import ada_boost_regression, extra_trees_regression, svr_poly, \\\r\n",
        "svr, svr_linear, svr_rbf, svr_poly, svr_sigmoid, knn_regression, sgd_regression, gradient_boosting_regression, \\\r\n",
        "random_forest_regression, extra_trees_regression, sgd_regression, xgboost_regression\r\n",
        "from sklearn.metrics import max_error, mean_squared_log_error\r\n",
        "\r\n",
        "\r\n",
        "# разделим выборку на тест и обучение \r\n",
        "score = []\r\n",
        "\r\n",
        "for i in range(5,6):\r\n",
        "  x_train = df_train[['X','Y']]\r\n",
        "  y_train = df_train['NTG']\r\n",
        "  x_train_split, x_test_split, y_train_split, y_test_split = train_test_split(x_train, y_train, test_size=0.33, random_state=42)\r\n",
        "\r\n",
        "  poly_reg = PolynomialFeatures(degree=i)\r\n",
        "  x_train_split  = poly_reg.fit_transform(x_train_split)\r\n",
        "  x_test_split = poly_reg.fit_transform(x_test_split)\r\n",
        "\r\n",
        "  scaler = MinMaxScaler(feature_range=(0.0, 1.0))\r\n",
        "  x_train_split = scaler.fit_transform(x_train_split)\r\n",
        "  x_test_split = scaler.transform(x_test_split)\r\n",
        "\r\n",
        "  regr = AdaBoostRegressor(base_estimator=None, learning_rate=1.6273721018635237,\r\n",
        "                    loss='linear', n_estimators=35, random_state=2100)\r\n",
        "  regr.fit(x_train_split, y_train_split)\r\n",
        "\r\n",
        "  y_train_pred = regr.predict(x_train_split)\r\n",
        "  y_test_pred = regr.predict(x_test_split)\r\n",
        "\r\n",
        "  ################################3\r\n",
        "  model = estim = HyperoptEstimator(regressor=svr_linear('my_gb'),\r\n",
        "                          max_evals=10, trial_timeout=10, seed=39,\r\n",
        "                          loss_fn=mean_squared_error)\r\n",
        "\r\n",
        "  model.fit(x_train_split, y_train_split)\r\n",
        "  y_train_pred_2 = model.predict(x_train_split)\r\n",
        "  y_test_pred_2 = model.predict(x_test_split)\r\n",
        "\r\n",
        "  al = 0.5\r\n",
        "  # y_train_pred = (al*y_train_pred + (1-al)*y_train_pred_2)\r\n",
        "  # y_test_pred = (al*y_test_pred + (1-al)*y_test_pred_2)\r\n",
        "  ###################################\r\n",
        "  estim = HyperoptEstimator(regressor=ada_boost_regression('my_gb'),\r\n",
        "                          max_evals=10, trial_timeout=10, seed=39,\r\n",
        "                          loss_fn=mean_squared_error)\r\n",
        "\r\n",
        "  estim.fit(x_train_split, y_train_split)\r\n",
        "  y_train_pred_3 = estim.predict(x_train_split)\r\n",
        "  y_test_pred_3 = estim.predict(x_test_split)\r\n",
        "\r\n",
        "\r\n",
        "  A = 0.3\r\n",
        "  B = 0.3\r\n",
        "  C = 1 - A - B\r\n",
        "  y_train_pred = A*y_train_pred + + B*y_train_pred_2 + C*y_train_pred_3\r\n",
        "  y_test_pred = A*y_test_pred + B*y_test_pred_2 + C*y_test_pred_3\r\n",
        "\r\n",
        "\r\n",
        "  print('MAE train: {:.3f}, test: {:.3f}'.format(\r\n",
        "          mean_absolute_error(y_train_split, y_train_pred),\r\n",
        "          mean_absolute_error(y_test_split, y_test_pred)))\r\n",
        "  print('MSE train: {:.3f}, test: {:.3f}'.format(\r\n",
        "          mean_squared_error(y_train_split, y_train_pred),\r\n",
        "          mean_squared_error(y_test_split, y_test_pred)))\r\n",
        "  print('R^2 train: {:.3f}, test: {:.3f}'.format(\r\n",
        "          r2_score(y_train_split, y_train_pred),\r\n",
        "          r2_score(y_test_split, y_test_pred)))\r\n",
        "  print('RMSE train: {:.3f}, test: {:.3f}'.format(\r\n",
        "          math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\r\n",
        "          math.sqrt(mean_squared_error(y_test_split, y_test_pred))))\r\n",
        "  print('Cтепень равняется ', i)\r\n",
        "  print('######################################')  \r\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 14.41it/s, best loss: 0.0050743404204556366]\n",
            "100%|██████████| 1/1 [00:00<00:00, 30.85it/s, best loss: 0.0050743404204556366]\n",
            "100%|██████████| 1/1 [00:00<00:00, 29.98it/s, best loss: 0.0050743404204556366]\n",
            "100%|██████████| 1/1 [00:00<00:00, 27.35it/s, best loss: 0.0050743404204556366]\n",
            "100%|██████████| 1/1 [00:00<00:00, 29.55it/s, best loss: 0.0050743404204556366]\n",
            "100%|██████████| 1/1 [00:00<00:00, 29.57it/s, best loss: 0.0050743404204556366]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.82it/s, best loss: 0.0050743404204556366]\n",
            "100%|██████████| 1/1 [00:00<00:00, 31.35it/s, best loss: 0.0050743404204556366]\n",
            "100%|██████████| 1/1 [00:00<00:00, 25.70it/s, best loss: 0.0050743404204556366]\n",
            "100%|██████████| 1/1 [00:00<00:00, 29.69it/s, best loss: 0.0050743404204556366]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.34it/s, best loss: 0.004042153039546323]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.41it/s, best loss: 0.004042153039546323]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.38s/it, best loss: 0.0030080621865901163]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.96it/s, best loss: 0.00267824472350862]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.46it/s, best loss: 0.00267824472350862]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.13it/s, best loss: 0.00267824472350862]\n",
            "100%|██████████| 1/1 [00:00<00:00, 14.47it/s, best loss: 0.00267824472350862]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.31it/s, best loss: 0.00267824472350862]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.65it/s, best loss: 0.00267824472350862]\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.54it/s, best loss: 0.00267824472350862]\n",
            "MAE train: 0.040, test: 0.048\n",
            "MSE train: 0.002, test: 0.003\n",
            "R^2 train: 0.606, test: 0.341\n",
            "RMSE train: 0.047, test: 0.055\n",
            "Cтепень равняется  5\n",
            "######################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udPRPo2DOXYi",
        "outputId": "9625d390-26f9-40ee-c119-e1a0c068c66e"
      },
      "source": [
        "# Вытащим сами алгоритмы\r\n",
        "print(model.best_model()['learner'])\r\n",
        "print(estim.best_model()['learner'])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVR(C=0.00011055634849084026, cache_size=512, coef0=0.0, degree=1,\n",
            "    epsilon=0.001115347080173807, gamma='auto', kernel='linear',\n",
            "    max_iter=170274026.0, shrinking=False, tol=0.0002988612959169446,\n",
            "    verbose=False)\n",
            "AdaBoostRegressor(base_estimator=None, learning_rate=0.19877223857045706,\n",
            "                  loss='square', n_estimators=285, random_state=3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gII2YngaM5k"
      },
      "source": [
        "Попытка обучиться по ошибке 1го обучения - не дела результатов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw1v9UL5Vw7s",
        "outputId": "f5674eb1-ca86-4a4c-ff7e-4a37f20c8a28"
      },
      "source": [
        "\r\n",
        "\r\n",
        "x_train = df_train[['X','Y']]\r\n",
        "y_train = df_train['NTG']\r\n",
        "x_train_split, x_test_split, y_train_split, y_test_split = train_test_split(x_train, y_train, test_size=0.33, random_state=42)\r\n",
        "\r\n",
        "poly_reg = PolynomialFeatures(degree=5)\r\n",
        "x_train_split  = poly_reg.fit_transform(x_train_split)\r\n",
        "x_test_split = poly_reg.fit_transform(x_test_split)\r\n",
        "\r\n",
        "scaler = MinMaxScaler(feature_range=(0.0, 1.0))\r\n",
        "x_train_split = scaler.fit_transform(x_train_split)\r\n",
        "x_test_split = scaler.transform(x_test_split)\r\n",
        "\r\n",
        "regr = AdaBoostRegressor(base_estimator=None, learning_rate=1.6273721018635237,\r\n",
        "                  loss='linear', n_estimators=35, random_state=2100)\r\n",
        "\r\n",
        "# model = SVR(C=0.00011055634849084026, cache_size=512, coef0=0.0, degree=1,\r\n",
        "#     epsilon=0.001115347080173807, gamma='auto', kernel='linear',\r\n",
        "#     max_iter=170274026.0, shrinking=False, tol=0.0002988612959169446,\r\n",
        "#     verbose=False)\r\n",
        "\r\n",
        "regr.fit(x_train_split, y_train_split)\r\n",
        "\r\n",
        "y_train_pred_1 = regr.predict(x_train_split)\r\n",
        "\r\n",
        "########################################33\r\n",
        "y_MIDLE = y_train_split - y_train_pred\r\n",
        "model = HyperoptEstimator(regressor=ada_boost_regression('reg'), preprocessing=any_preprocessing('pre'), algo=tpe.suggest, max_evals=20, trial_timeout=30)\r\n",
        "model.fit(x_train_split, y_MIDLE)\r\n",
        "\r\n",
        "y_train_pred_2 = model.predict(x_train_split)\r\n",
        "# y_train_pred = y_train_pred + model.predict(x_train_split)\r\n",
        "# y_test_pred = regr.predict(x_test_split) +  model.predict(x_test_split)\r\n",
        "\r\n",
        "########################################33\r\n",
        "y_MIDLE_2 = y_train_split - y_train_pred_1 - y_train_pred_2\r\n",
        "est = HyperoptEstimator(regressor=svr_linear('reg'), preprocessing=any_preprocessing('pre'), algo=tpe.suggest, max_evals=20, trial_timeout=30)\r\n",
        "est.fit(x_train_split, y_MIDLE_2)\r\n",
        "\r\n",
        "y_train_pred = regr.predict(x_train_split) + model.predict(x_train_split) + est.predict(x_train_split)\r\n",
        "y_test_pred = regr.predict(x_test_split) +  model.predict(x_test_split) + est.predict(x_test_split)\r\n",
        "\r\n",
        "\r\n",
        "print('MAE train: {:.3f}, test: {:.3f}'.format(\r\n",
        "        mean_absolute_error(y_train_split, y_train_pred),\r\n",
        "        mean_absolute_error(y_test_split, y_test_pred)))\r\n",
        "print('MSE train: {:.3f}, test: {:.3f}'.format(\r\n",
        "        mean_squared_error(y_train_split, y_train_pred),\r\n",
        "        mean_squared_error(y_test_split, y_test_pred)))\r\n",
        "print('R^2 train: {:.3f}, test: {:.3f}'.format(\r\n",
        "        r2_score(y_train_split, y_train_pred),\r\n",
        "        r2_score(y_test_split, y_test_pred)))\r\n",
        "print('RMSE train: {:.3f}, test: {:.3f}'.format(\r\n",
        "        math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\r\n",
        "        math.sqrt(mean_squared_error(y_test_split, y_test_pred))))\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.62it/s, best loss: 0.4424185652546423]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.21it/s, best loss: 0.2552164137752905]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.31it/s, best loss: 0.2552164137752905]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.98it/s, best loss: 0.2552164137752905]\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.07it/s, best loss: 0.24737499736269164]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.19it/s, best loss: 0.21839262129756576]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.94it/s, best loss: 0.21839262129756576]\n",
            "100%|██████████| 1/1 [00:00<00:00, 13.04it/s, best loss: 0.21839262129756576]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.18it/s, best loss: 0.21839262129756576]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=21, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.53it/s, best loss: 0.21839262129756576]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.07it/s, best loss: 0.21839262129756576]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.32it/s, best loss: 0.21839262129756576]\n",
            "100%|██████████| 1/1 [00:00<00:00, 14.73it/s, best loss: 0.21839262129756576]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.13it/s, best loss: 0.21839262129756576]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.58it/s, best loss: 0.21839262129756576]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.16s/it, best loss: 0.18033560957289296]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.17it/s, best loss: 0.18033560957289296]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.29it/s, best loss: 0.18033560957289296]\n",
            "100%|██████████| 1/1 [00:00<00:00, 14.55it/s, best loss: 0.18033560957289296]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.29it/s, best loss: 0.18033560957289296]\n",
            "100%|██████████| 1/1 [00:00<00:00, 22.67it/s, best loss: 1.0161253928128677]\n",
            "100%|██████████| 1/1 [00:00<00:00, 21.36it/s, best loss: 1.0161253928128287]\n",
            "100%|██████████| 1/1 [00:00<00:00, 19.84it/s, best loss: 1.0161253928128287]\n",
            "100%|██████████| 1/1 [00:00<00:00, 20.30it/s, best loss: 1.0161253928128287]\n",
            "100%|██████████| 1/1 [00:00<00:00, 20.41it/s, best loss: 1.0161253928128287]\n",
            "100%|██████████| 1/1 [00:00<00:00, 19.47it/s, best loss: 1.0161253928128287]\n",
            "100%|██████████| 1/1 [00:00<00:00, 21.08it/s, best loss: 0.8652843011075192]\n",
            "100%|██████████| 1/1 [00:00<00:00, 23.27it/s, best loss: 0.8652843011075192]\n",
            "100%|██████████| 1/1 [00:00<00:00, 19.16it/s, best loss: 0.8652843011075192]\n",
            "100%|██████████| 1/1 [00:00<00:00, 21.72it/s, best loss: 0.8652843011075192]\n",
            "100%|██████████| 1/1 [00:00<00:00, 20.64it/s, best loss: 0.8652843011075192]\n",
            "100%|██████████| 1/1 [00:00<00:00, 17.18it/s, best loss: 0.8232516624888839]\n",
            "100%|██████████| 1/1 [00:00<00:00, 23.22it/s, best loss: 0.8232516624888839]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.41s/it, best loss: 0.7735810637346072]\n",
            "100%|██████████| 1/1 [00:00<00:00, 22.73it/s, best loss: 0.7735810637346072]\n",
            "100%|██████████| 1/1 [00:00<00:00, 21.47it/s, best loss: 0.7735810637346072]\n",
            "100%|██████████| 1/1 [00:00<00:00, 21.19it/s, best loss: 0.7735810637346072]\n",
            "100%|██████████| 1/1 [00:00<00:00, 21.87it/s, best loss: 0.7735810637346072]\n",
            "100%|██████████| 1/1 [00:00<00:00, 18.97it/s, best loss: 0.7735810637346072]\n",
            "100%|██████████| 1/1 [00:00<00:00, 21.44it/s, best loss: 0.7735810637346072]\n",
            "MAE train: 0.033, test: 0.051\n",
            "MSE train: 0.002, test: 0.003\n",
            "R^2 train: 0.725, test: 0.249\n",
            "RMSE train: 0.039, test: 0.059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ePgsrP3xx87"
      },
      "source": [
        "### *KNeighborsRegressor*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LzPyObuxydr",
        "outputId": "6477262d-1f49-4391-d993-e31d591447a7"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html?highlight=kneighborsregressor#sklearn.neighbors.KNeighborsRegressor\n",
        "\n",
        "regr = KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='chebyshev',\n",
        "                    metric_params=None, n_jobs=1, n_neighbors=2, p=0,\n",
        "                    weights='uniform')\n",
        "\n",
        "regr.fit(x_train_split, y_train_split)\n",
        "\n",
        "y_train_pred = regr.predict(x_train_split)\n",
        "y_test_pred = regr.predict(x_test_split)\n",
        "\n",
        "print('MAE train: {:.3f}, test: {:.3f}'.format(\n",
        "        mean_absolute_error(y_train_split, y_train_pred),\n",
        "        mean_absolute_error(y_test_split, y_test_pred)))\n",
        "print('MSE train: {:.3f}, test: {:.3f}'.format(\n",
        "        mean_squared_error(y_train_split, y_train_pred),\n",
        "        mean_squared_error(y_test_split, y_test_pred)))\n",
        "print('R^2 train: {:.3f}, test: {:.3f}'.format(\n",
        "        r2_score(y_train_split, y_train_pred),\n",
        "        r2_score(y_test_split, y_test_pred)))\n",
        "print('RMSE train: {:.3f}, test: {:.3f}'.format(\n",
        "        math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\n",
        "        math.sqrt(mean_squared_error(y_test_split, y_test_pred))))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE train: 0.030, test: 0.048\n",
            "MSE train: 0.001, test: 0.004\n",
            "R^2 train: 0.730, test: 0.177\n",
            "RMSE train: 0.038, test: 0.062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M1DuqsOvdFT"
      },
      "source": [
        "### Lasso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q84WWJQvdFT",
        "outputId": "82a61eb1-019f-4894-b17c-4e9d71e4021c"
      },
      "source": [
        "def lasso_regresion():\n",
        "  \"\"\"Обучим лассо регрессию\"\"\"\n",
        "  lasso = Lasso(alpha=0.1)\n",
        "  lasso.fit(x_train_split, y_train_split)\n",
        "  y_train_pred = lasso.predict(x_train_split)\n",
        "  y_test_pred = lasso.predict(x_test_split)\n",
        "\n",
        "  # вывод оценок обучения\n",
        "  print('MAE train: {:.3f}, test: {:.3f}'.format(\n",
        "          mean_absolute_error(y_train_split, y_train_pred),\n",
        "          mean_absolute_error(y_test_split, y_test_pred)))\n",
        "  print('MSE train: {:.3f}, test: {:.3f}'.format(\n",
        "          mean_squared_error(y_train_split, y_train_pred),\n",
        "          mean_squared_error(y_test_split, y_test_pred)))\n",
        "  print('R^2 train: {:.3f}, test: {:.3f}'.format(\n",
        "          r2_score(y_train_split, y_train_pred),\n",
        "          r2_score(y_test_split, y_test_pred)))\n",
        "  print('RMSE train: {:.3f}, test: {:.3f}'.format(\n",
        "          math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\n",
        "          math.sqrt(mean_squared_error(y_test_split, y_test_pred))))\n",
        "  \n",
        "lasso_regresion()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE train: 0.062, test: 0.055\n",
            "MSE train: 0.005, test: 0.005\n",
            "R^2 train: 0.000, test: -0.007\n",
            "RMSE train: 0.074, test: 0.068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY0RkONevdFU"
      },
      "source": [
        "### ElasticNet¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylle0elgvdFW",
        "outputId": "e6b4b18a-9c48-41ba-e94a-46bc3da2af36"
      },
      "source": [
        "def Elastic_regresion():\n",
        "\n",
        "  est_acc = ElasticNet()\n",
        "  est_acc.fit(x_train_split, y_train_split)\n",
        "  y_train_pred = est_acc.predict(x_train_split)\n",
        "  y_test_pred = est_acc.predict(x_test_split)\n",
        "\n",
        "  print('MSE train: {:.3f}, test: {:.3f}'.format(\n",
        "          mean_squared_error(y_train_split, y_train_pred),\n",
        "          mean_squared_error(y_test_split, y_test_pred)))\n",
        "  print('R^2 train: {:.3f}, test: {:.3f}'.format(\n",
        "          r2_score(y_train_split, y_train_pred),\n",
        "          r2_score(y_test_split, y_test_pred)))\n",
        "  print('RMSE train: {:.3f}, test: {:.3f}'.format(\n",
        "          math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\n",
        "          math.sqrt(mean_squared_error(y_test_split, y_test_pred))))\n",
        "  \n",
        "Elastic_regresion()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE train: 0.005, test: 0.005\n",
            "R^2 train: 0.000, test: -0.007\n",
            "RMSE train: 0.074, test: 0.068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfawXh6mMlFz"
      },
      "source": [
        "# from sklearn.metrics import make_scorer\n",
        "\n",
        "# def Elastic_regresion_GRID():\n",
        "#   parametersGrid = {\"max_iter\": [500],\n",
        "#                     \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
        "#                     \"l1_ratio\": np.arange(0.0, 1.0, 0.1)}\n",
        "\n",
        "#   def RMSE(y_true, y_pred):\n",
        "#       return math.sqrt(mean_squared_error(y_true, y_pred))\n",
        "#   def RMSE_2():\n",
        "#     return make_scorer(RMSE, greater_is_better=False)\n",
        "\n",
        "#   # поиск по сетке\n",
        "#   eNet = ElasticNet()\n",
        "#   grid = GridSearchCV(eNet, parametersGrid, scoring=RMSE_2(), cv=10)\n",
        "#   grid.fit(df_train[['X','Y']], df_train['NTG']*100)\n",
        "#   print(grid.best_score_)\n",
        "#   print(grid.best_estimator_)\n",
        "\n",
        "# Elastic_regresion_GRID()"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW-hT6QdvdFa"
      },
      "source": [
        "### Ridge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZzRhRmUvdFc",
        "outputId": "70793b11-5e35-4b60-f2b5-d56bd5220d27"
      },
      "source": [
        "def ridge_regresion():\n",
        "  \n",
        "  ridge = Ridge(alpha=0.1)\n",
        "  ridge.fit(x_train_split, y_train_split)\n",
        "  y_train_pred = ridge.predict(x_train_split)\n",
        "  y_test_pred = ridge.predict(x_test_split)\n",
        "\n",
        "  print('MAE train: {:.3f}, test: {:.3f}'.format(\n",
        "          mean_absolute_error(y_train_split, y_train_pred),\n",
        "          mean_absolute_error(y_test_split, y_test_pred)))\n",
        "  print('MSE train: {:.3f}, test: {:.3f}'.format(\n",
        "          mean_squared_error(y_train_split, y_train_pred),\n",
        "          mean_squared_error(y_test_split, y_test_pred)))\n",
        "  print('R^2 train: {:.3f}, test: {:.3f}'.format(\n",
        "          r2_score(y_train_split, y_train_pred),\n",
        "          r2_score(y_test_split, y_test_pred)))\n",
        "  print('RMSE train: {:.3f}, test: {:.3f}'.format(\n",
        "          math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\n",
        "          math.sqrt(mean_squared_error(y_test_split, y_test_pred))))\n",
        "  \n",
        "ridge_regresion()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE train: 0.060, test: 0.053\n",
            "MSE train: 0.005, test: 0.004\n",
            "R^2 train: 0.066, test: 0.028\n",
            "RMSE train: 0.072, test: 0.067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9maSxSCBvdFd"
      },
      "source": [
        "### Полиномиальная регерссия\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHqNqEQFvdFe",
        "outputId": "b5a9175c-d252-4693-c6fe-c247e968ed9c"
      },
      "source": [
        "# взял из https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
        "\n",
        "\n",
        "def polinom_regresion():\n",
        "\n",
        "  poly_reg = PolynomialFeatures(degree=4, interaction_only = True, include_bias = True)\n",
        "  X_poly_train = poly_reg.fit_transform(x_train_split)\n",
        "  X_poly_test = poly_reg.fit_transform(x_test_split)\n",
        "\n",
        "  pol_reg = LinearRegression()\n",
        "\n",
        "  pol_reg.fit(X_poly_train, y_train_split)\n",
        "  y_train_pred = pol_reg.predict(X_poly_train)\n",
        "  y_test_pred = pol_reg.predict(X_poly_test)\n",
        "\n",
        "  print('MAE train: {:.3f}, test: {:.3f}'.format(\n",
        "          mean_absolute_error(y_train_split, y_train_pred),\n",
        "          mean_absolute_error(y_test_split, y_test_pred)))\n",
        "  print('MSE train: {:.3f}, test: {:.3f}'.format(\n",
        "          mean_squared_error(y_train_split, y_train_pred),\n",
        "          mean_squared_error(y_test_split, y_test_pred)))\n",
        "  print('R^2 train: {:.3f}, test: {:.3f}'.format(\n",
        "          r2_score(y_train_split, y_train_pred),\n",
        "          r2_score(y_test_split, y_test_pred)))\n",
        "  print('RMSE train: {:.3f}, test: {:.3f}'.format(\n",
        "          math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\n",
        "          math.sqrt(mean_squared_error(y_test_split, y_test_pred))))\n",
        "\n",
        "polinom_regresion()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE train: 0.059, test: 0.052\n",
            "MSE train: 0.005, test: 0.004\n",
            "R^2 train: 0.065, test: 0.064\n",
            "RMSE train: 0.072, test: 0.066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqne-9QlJCXu"
      },
      "source": [
        "### Полиномиальнаяр регерссия по сетке"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1zq0jmwJB9F"
      },
      "source": [
        "p_degree = range(1,20)\r\n",
        "p_interaction_only = [True, False]\r\n",
        "p_include_bias = [True, False]\r\n",
        "\r\n",
        "list_acc_score = []\r\n",
        "list_degree = [] \r\n",
        "list_interaction_only = []\r\n",
        "list_include_bias = []\r\n",
        "\r\n",
        "for degree in p_degree:\r\n",
        "    for interaction_only in p_interaction_only:\r\n",
        "        for include_bias in p_include_bias:\r\n",
        "              \r\n",
        "              list_degree.append(degree)\r\n",
        "              list_interaction_only.append(interaction_only)\r\n",
        "              list_include_bias.append(include_bias)\r\n",
        "\r\n",
        "              # define model\r\n",
        "              poly_reg = PolynomialFeatures(degree=degree, \r\n",
        "                                            interaction_only = interaction_only, include_bias = include_bias)\r\n",
        "              X_poly_train = poly_reg.fit_transform(x_train_split)\r\n",
        "              X_poly_test = poly_reg.fit_transform(x_test_split)\r\n",
        "\r\n",
        "              pol_reg = LinearRegression()\r\n",
        "              pol_reg.fit(X_poly_train, y_train_split)\r\n",
        "              \r\n",
        "              y_train_pred = pol_reg.predict(X_poly_train)\r\n",
        "              y_test_pred = pol_reg.predict(X_poly_test)\r\n",
        "\r\n",
        "\r\n",
        "              # #   проверка качества по кросс валедации\r\n",
        "              acc = math.sqrt(mean_squared_error(y_test_split, y_test_pred))\r\n",
        "\r\n",
        "              list_acc_score.append(acc)\r\n",
        "\r\n",
        "\r\n",
        "acc_score = pd.DataFrame()\r\n",
        "acc_score[\"acc_scire\"] = list_acc_score        \r\n",
        "acc_score[\"degree\"] = list_degree     \r\n",
        "acc_score[\"interaction_only\"] = list_interaction_only\r\n",
        "acc_score[\"include_bias\"] = list_include_bias\r\n",
        "\r\n",
        "acc_score.sort_values(by = 'acc_scire', ascending = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R3biFiGg6Yd"
      },
      "source": [
        "### Случайный лес классификатор"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3sl_Omhg_E-",
        "outputId": "24c208d2-62e9-4cd9-9e3e-81ba48155a32"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.metrics import r2_score as r2, mean_absolute_error as mae, mean_squared_error as mse, accuracy_score\r\n",
        "\r\n",
        "# взял из https://habr.com/ru/post/533470/\r\n",
        "\r\n",
        "model = RandomForestRegressor(random_state=42, max_depth=20)\r\n",
        "model.fit(x_train_split, y_train_split)\r\n",
        "\r\n",
        "y_train_pred = model.predict(x_train_split)\r\n",
        "y_test_pred = model.predict(x_test_split)\r\n",
        "\r\n",
        "print('MSE train: {:.3f}, test: {:.3f}'.format(\r\n",
        "      mean_squared_error(y_train_split, y_train_pred),\r\n",
        "      mean_squared_error(y_test_split, y_test_pred)))\r\n",
        "print('R^2 train: {:.3f}, test: {:.3f}'.format(\r\n",
        "      r2_score(y_train_split, y_train_pred),\r\n",
        "      r2_score(y_test_split, y_test_pred)))\r\n",
        "print('RMSE train: {:.3f}, test: {:.3f}'.format(\r\n",
        "      math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\r\n",
        "      math.sqrt(mean_squared_error(y_test_split, y_test_pred))))\r\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE train: 0.000, test: 0.004\n",
            "R^2 train: 0.918, test: 0.148\n",
            "RMSE train: 0.021, test: 0.063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_rvFX3hh6tG"
      },
      "source": [
        "### Cлуйчайный лес по сетке"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6q2NCVUh5qp",
        "outputId": "50966280-9c64-47c1-a058-fc0bb30bcec3"
      },
      "source": [
        "model = RandomForestRegressor(random_state=30)\r\n",
        "param_grid = { \"n_estimators\" : [250, 300],\r\n",
        "           \"criterion\" : [\"mse\", \"mae\"],\r\n",
        "           \"max_features\" : [\"auto\", \"sqrt\", \"log2\"],\r\n",
        "           \"max_depth\" : [10, 20],\r\n",
        "           \"min_samples_split\" : [2, 4] ,\r\n",
        "           \"min_samples_leaf\" : [1,2,3,5] \r\n",
        "            }\r\n",
        "\r\n",
        "grid_search = GridSearchCV(model, param_grid, scoring = 'neg_mean_squared_error', n_jobs=-1, cv=2)\r\n",
        "grid_search.fit(df_train[['X','Y']], df_train['NTG'])\r\n",
        "\r\n",
        "print(grid_search.best_params_)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'criterion': 'mae', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 250}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyC40zzEmqeR",
        "outputId": "7de1f5d6-92a1-4e2f-ec87-c7b7f37cbcab"
      },
      "source": [
        "print(grid_search.best_score_)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.004765869042704049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SXDB1OalsEY",
        "outputId": "f5fa4ab7-5011-4b8e-dc30-c1363e185e55"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "\r\n",
        "# разделим выборку на тест и обучение \r\n",
        "\r\n",
        "x_train = df_train[['X','Y']]\r\n",
        "y_train = df_train['NTG']\r\n",
        "x_train_split, x_test_split, y_train_split, y_test_split = train_test_split(x_train, y_train, test_size=0.33, random_state=42)\r\n",
        "\r\n",
        "poly_reg = PolynomialFeatures(degree=2)\r\n",
        "x_train_split  = poly_reg.fit_transform(x_train_split)\r\n",
        "x_test_split = poly_reg.fit_transform(x_test_split)\r\n",
        "\r\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\r\n",
        "x_train_split = scaler.fit_transform(x_train_split)\r\n",
        "x_test_split = scaler.transform(x_test_split)\r\n",
        "\r\n",
        "\r\n",
        "model = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\r\n",
        "                      max_depth=20, max_features='sqrt', max_leaf_nodes=None,\r\n",
        "                      max_samples=None, min_impurity_decrease=0.0,\r\n",
        "                      min_impurity_split=None, min_samples_leaf=2,\r\n",
        "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\r\n",
        "                      n_estimators=250, n_jobs=None, oob_score=False,\r\n",
        "                      random_state=30, verbose=0, warm_start=False)\r\n",
        "\r\n",
        "model.fit(x_train_split,y_train_split)\r\n",
        "\r\n",
        "y_train_pred = model.predict(x_train_split)\r\n",
        "y_test_pred = model.predict(x_test_split)\r\n",
        "\r\n",
        "print('MSE train: {:.3f}, test: {:.3f}'.format(\r\n",
        "      mean_squared_error(y_train_split, y_train_pred),\r\n",
        "      mean_squared_error(y_test_split, y_test_pred)))\r\n",
        "print('R^2 train: {:.3f}, test: {:.3f}'.format(\r\n",
        "      r2_score(y_train_split, y_train_pred),\r\n",
        "      r2_score(y_test_split, y_test_pred)))\r\n",
        "print('RMSE train: {:.3f}, test: {:.3f}'.format(\r\n",
        "      math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\r\n",
        "      math.sqrt(mean_squared_error(y_test_split, y_test_pred))))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE train: 0.001, test: 0.003\n",
            "R^2 train: 0.758, test: 0.277\n",
            "RMSE train: 0.036, test: 0.058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgRGSCCzkdfX",
        "outputId": "bf072854-74e2-4017-ac75-941d1f4a65cc"
      },
      "source": [
        "grid_search.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.004765869042704049"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tfy8a1BtPuF"
      },
      "source": [
        "### ЗАМЕТКА - метрики скайлерн\r\n",
        "\r\n",
        "https://scikit-learn.org/stable/modules/grid_search.html#multimetric-grid-search\r\n",
        "\r\n",
        "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\r\n",
        "\r\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor\r\n",
        "\r\n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html\r\n",
        "\r\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\r\n",
        "\r\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RkhDJocoZKC"
      },
      "source": [
        "### hpsklearn "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIAA95XWojPh",
        "outputId": "d1bdef88-8c46-44c8-9f67-3bb40f2d5417"
      },
      "source": [
        "!pip install hyperopt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt) (4.41.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt) (2.5)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt) (3.11.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.19.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRTnxod4o2Yk",
        "outputId": "3416578c-6916-4d90-e3fe-2936e1f41eab"
      },
      "source": [
        "# !pip install hpsklearn\r\n",
        "!pip install git+https://github.com/hyperopt/hyperopt-sklearn.git\r\n",
        "# взял из https://github.com/hyperopt/hyperopt-sklearn/issues/133"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/hyperopt/hyperopt-sklearn.git\n",
            "  Cloning https://github.com/hyperopt/hyperopt-sklearn.git to /tmp/pip-req-build-_nqknpap\n",
            "  Running command git clone -q https://github.com/hyperopt/hyperopt-sklearn.git /tmp/pip-req-build-_nqknpap\n",
            "Requirement already satisfied (use --upgrade to upgrade): hpsklearn==0.0.3 from git+https://github.com/hyperopt/hyperopt-sklearn.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.7/dist-packages (from hpsklearn==0.0.3) (0.1.2)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from hpsklearn==0.0.3) (1.3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hpsklearn==0.0.3) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from hpsklearn==0.0.3) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hpsklearn==0.0.3) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt->hpsklearn==0.0.3) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt->hpsklearn==0.0.3) (4.41.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt->hpsklearn==0.0.3) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt->hpsklearn==0.0.3) (3.11.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt->hpsklearn==0.0.3) (2.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->hpsklearn==0.0.3) (1.0.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt->hpsklearn==0.0.3) (4.4.2)\n",
            "Building wheels for collected packages: hpsklearn\n",
            "  Building wheel for hpsklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hpsklearn: filename=hpsklearn-0.0.3-cp37-none-any.whl size=26924 sha256=edfaa4435fcb50c372c8558c4edd1d8f3092cfcf6f272b04858bd1d52d27bb20\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-o58j1emh/wheels/28/93/20/67dca95c2aaa13466b4900ba79a7bab66022e50ce44f8a438d\n",
            "Successfully built hpsklearn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNQ3G0XStLVu"
      },
      "source": [
        "https://machinelearningmastery.com/hyperopt-for-automated-machine-learning-with-scikit-learn/\r\n",
        "\r\n",
        "http://hyperopt.github.io/hyperopt-sklearn/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQveWKFkvQ57",
        "outputId": "1c8da7dd-9638-441f-9eb0-a26730cd683c"
      },
      "source": [
        "  y_train_pred = model.predict(x_train_split)\n",
        "  y_test_pred = model.predict(x_test_split)\n",
        "\n",
        "  print('MSE train: {:.3f}, test: {:.3f}'.format(\n",
        "          mean_squared_error(y_train_split, y_train_pred),\n",
        "          mean_squared_error(y_test_split, y_test_pred)))\n",
        "  print('R^2 train: {:.3f}, test: {:.3f}'.format(\n",
        "          r2_score(y_train_split, y_train_pred),\n",
        "          r2_score(y_test_split, y_test_pred)))\n",
        "  print('RMSE train: {:.3f}, test: {:.3f}'.format(\n",
        "          math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\n",
        "          math.sqrt(mean_squared_error(y_test_split, y_test_pred))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE train: 0.001, test: 0.003\n",
            "R^2 train: 0.763, test: 0.283\n",
            "RMSE train: 0.036, test: 0.058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFwfUITHoYvf",
        "outputId": "f5145559-8233-4226-d81b-9b3c6983bd18"
      },
      "source": [
        "\r\n",
        "\r\n",
        "# example of hyperopt-sklearn for the housing regression dataset\r\n",
        "\r\n",
        "# https://laptrinhx.com/hyperopt-for-automated-machine-learning-with-scikit-learn-1421923572/\r\n",
        "\r\n",
        "from pandas import read_csv\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from hpsklearn import HyperoptEstimator\r\n",
        "from hpsklearn import any_regressor\r\n",
        "from hpsklearn import any_preprocessing\r\n",
        "from hyperopt import tpe\r\n",
        "\r\n",
        "# define search\r\n",
        "model = HyperoptEstimator(regressor=any_regressor('reg'), preprocessing=any_preprocessing('pre'), loss_fn=mean_squared_error, algo=tpe.suggest, max_evals=100, trial_timeout=90)\r\n",
        "# perform the search\r\n",
        "\r\n",
        "# model.fit(x_train_split.values.astype('float32'), y_train_split.values.astype('float32'))\r\n",
        "model.fit(x_train_split.astype('float32'), y_train_split.astype('float32'))\r\n",
        "# summarize performance\r\n",
        "mae = model.score(x_test_split, y_test_split)\r\n",
        "print(\"MAE: %.3f\" % mae)\r\n",
        "# summarize the best model\r\n",
        "print(model.best_model())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  5.34it/s, best loss: 0.0035636307891779924]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.94it/s, best loss: 0.0035636307891779924]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.91it/s, best loss: 0.0035636307891779924]\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.99it/s, best loss: 0.0035636307891779924]\n",
            "[12:02:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.28it/s, best loss: 0.0035636307891779924]\n",
            "[12:02:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.63it/s, best loss: 0.0035636307891779924]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.12it/s, best loss: 0.0035636307891779924]\n",
            "100%|██████████| 1/1 [00:04<00:00,  4.07s/it, best loss: 0.0025034073020518805]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.10s/it, best loss: 0.0025034073020518805]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.96s/it, best loss: 0.0025034073020518805]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.15it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.79it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.07it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.94it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.85it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.96it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.20it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.27it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.19it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.58it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.50s/it, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.70it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:04<00:00,  4.13s/it, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.37it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.61it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.11it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.14it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.18it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.01it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.58s/it, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.27s/it, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.71it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.92it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.98it/s, best loss: 0.0021230373711925237]\n",
            "[12:03:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.71it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.84it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.74it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.56it/s, best loss: 0.0021230373711925237]\n",
            "[12:03:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.99it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.41s/it, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.62s/it, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.54it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.99it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.87s/it, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.20it/s, best loss: 0.0021230373711925237]\n",
            "[12:03:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.84it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.95it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.59it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.40it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.52it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.39it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.32it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.33it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.79it/s, best loss: 0.0021230373711925237]\n",
            "[12:03:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.57it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.28it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.66it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.84it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.57it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.88it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.82it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.25it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.90it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.10it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.46it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.90it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.82it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.28it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.31it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.55it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.84it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.98it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.12s/it, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.48it/s, best loss: 0.0021230373711925237]\n",
            "[12:03:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.11it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.44it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.81it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.13it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.48it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.59it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.51it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.49it/s, best loss: 0.0021230373711925237]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.28s/it, best loss: 0.0010727424654032843]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.09s/it, best loss: 0.0010727424654032843]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.20s/it, best loss: 0.0010727424654032843]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.21s/it, best loss: 0.0010727424654032843]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.36s/it, best loss: 0.0010727424654032843]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.68s/it, best loss: 0.0010727424654032843]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.52it/s, best loss: 0.0010727424654032843]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.01s/it, best loss: 0.0010727424654032843]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.16it/s, best loss: 0.0010727424654032843]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.02it/s, best loss: 0.0010727424654032843]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.12s/it, best loss: 0.0010727424654032843]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.61it/s, best loss: 0.0010588525005058448]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.93it/s, best loss: 0.0010588525005058448]\n",
            "[12:04:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.09it/s, best loss: 0.0010588525005058448]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.90it/s, best loss: 0.0010588525005058448]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.74it/s, best loss: 0.0010588525005058448]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.14it/s, best loss: 0.0010588525005058448]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.87it/s, best loss: 0.0010588525005058448]\n",
            "MAE: 0.262\n",
            "{'learner': GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
            "                          init=None, learning_rate=0.0992062455031351,\n",
            "                          loss='lad', max_depth=4, max_features='sqrt',\n",
            "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                          min_impurity_split=None, min_samples_leaf=1,\n",
            "                          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                          n_estimators=208, n_iter_no_change=None,\n",
            "                          presort='deprecated', random_state=3,\n",
            "                          subsample=0.9087422704533004, tol=0.0001,\n",
            "                          validation_fraction=0.1, verbose=0, warm_start=False), 'preprocs': (StandardScaler(copy=True, with_mean=True, with_std=True),), 'ex_preprocs': ()}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gx5DDwYtFXn"
      },
      "source": [
        "{'learner': AdaBoostRegressor(base_estimator=None, learning_rate=1.6273721018635237,\r\n",
        "                  loss='linear', n_estimators=35, random_state=2), 'preprocs': (MinMaxScaler(copy=True, feature_range=(0.0, 1.0)),), 'ex_preprocs': ()}\r\n",
        "\r\n",
        "\r\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjGjqeVUtkYv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c106F88Nuxy6",
        "outputId": "422901ad-5f6c-4424-b765-af5e870ca3d5"
      },
      "source": [
        "print(math.sqrt(mean_squared_error(y_test_split, estim.predict(x_test_split))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.06528064105336184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izuUgHCj0iJV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ya2ooGk0fD2"
      },
      "source": [
        "*HyperoptEstimator* + xgboost_regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKMp9F1A1psm",
        "outputId": "d2dc4c1b-35a4-4383-b54f-c10d30821d83"
      },
      "source": [
        "from hpsklearn import HyperoptEstimator, xgboost_regression, random_forest_regression\r\n",
        "# # https://www.kaggle.com/ilialar/hyperparameters-tunning-with-hyperopt\r\n",
        "\r\n",
        "estim = HyperoptEstimator(regressor=xgboost_regression('my_gb'), max_evals=200, trial_timeout=50, seed=39)\r\n",
        "\r\n",
        "estim.fit(x_train_split, y_train_split)\r\n",
        "\r\n",
        "print(mean_squared_error(y_test_split, estim.predict(x_test_split)))\r\n",
        "print(math.sqrt(mean_squared_error(y_test_split, estim.predict(x_test_split))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[17:01:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.90it/s, best loss: 1.1157454718575508]\n",
            "[17:01:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.05it/s, best loss: 1.1157454718575508]\n",
            "[17:01:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.37it/s, best loss: 0.7078892611203441]\n",
            "[17:01:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.39it/s, best loss: 0.7078892611203441]\n",
            "[17:01:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.62it/s, best loss: 0.7078892611203441]\n",
            "[17:01:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.43it/s, best loss: 0.7078892611203441]\n",
            "[17:01:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.96it/s, best loss: 0.7078892611203441]\n",
            "[17:01:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.20it/s, best loss: 0.7078892611203441]\n",
            "[17:01:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.94it/s, best loss: 0.7078892611203441]\n",
            "[17:01:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.06it/s, best loss: 0.7078892611203441]\n",
            "[17:01:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.66it/s, best loss: 0.414389483524761]\n",
            "[17:01:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 15.62it/s, best loss: 0.414389483524761]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 13.04it/s, best loss: 0.414389483524761]\n",
            "[17:01:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.62it/s, best loss: 0.414389483524761]\n",
            "[17:01:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.54it/s, best loss: 0.414389483524761]\n",
            "[17:01:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.34it/s, best loss: 0.414389483524761]\n",
            "[17:01:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.51it/s, best loss: 0.414389483524761]\n",
            "[17:01:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.08it/s, best loss: 0.414389483524761]\n",
            "[17:01:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.37it/s, best loss: 0.414389483524761]\n",
            "[17:01:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.50it/s, best loss: 0.414389483524761]\n",
            "[17:01:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.76it/s, best loss: 0.414389483524761]\n",
            "[17:01:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.23it/s, best loss: 0.414389483524761]\n",
            "[17:01:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.13it/s, best loss: 0.414389483524761]\n",
            "[17:01:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.85it/s, best loss: 0.414389483524761]\n",
            "[17:01:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.36it/s, best loss: 0.414389483524761]\n",
            "[17:01:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.74it/s, best loss: 0.414389483524761]\n",
            "[17:01:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.67it/s, best loss: 0.414389483524761]\n",
            "[17:01:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.26it/s, best loss: 0.414389483524761]\n",
            "[17:01:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.56it/s, best loss: 0.414389483524761]\n",
            "[17:01:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.00it/s, best loss: 0.414389483524761]\n",
            "[17:01:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.70it/s, best loss: 0.414389483524761]\n",
            "[17:01:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.35it/s, best loss: 0.414389483524761]\n",
            "[17:01:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.17it/s, best loss: 0.414389483524761]\n",
            "[17:01:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.78it/s, best loss: 0.414389483524761]\n",
            "[17:01:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.35it/s, best loss: 0.414389483524761]\n",
            "[17:01:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.46it/s, best loss: 0.414389483524761]\n",
            "[17:01:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.03it/s, best loss: 0.414389483524761]\n",
            "[17:01:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.80it/s, best loss: 0.414389483524761]\n",
            "[17:01:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.25it/s, best loss: 0.414389483524761]\n",
            "[17:01:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.77it/s, best loss: 0.414389483524761]\n",
            "[17:01:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.26it/s, best loss: 0.414389483524761]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.36it/s, best loss: 0.414389483524761]\n",
            "[17:01:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.41it/s, best loss: 0.414389483524761]\n",
            "[17:01:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.43it/s, best loss: 0.414389483524761]\n",
            "[17:01:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.89it/s, best loss: 0.414389483524761]\n",
            "[17:01:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.31it/s, best loss: 0.414389483524761]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.99it/s, best loss: 0.414389483524761]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.68it/s, best loss: 0.414389483524761]\n",
            "[17:01:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.38it/s, best loss: 0.414389483524761]\n",
            "[17:01:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.74it/s, best loss: 0.414389483524761]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.72it/s, best loss: 0.414389483524761]\n",
            "[17:01:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.65it/s, best loss: 0.414389483524761]\n",
            "[17:01:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.96it/s, best loss: 0.414389483524761]\n",
            "[17:01:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.26it/s, best loss: 0.414389483524761]\n",
            "[17:01:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.87it/s, best loss: 0.414389483524761]\n",
            "[17:01:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.97it/s, best loss: 0.414389483524761]\n",
            "[17:01:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.31it/s, best loss: 0.414389483524761]\n",
            "[17:01:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.21it/s, best loss: 0.414389483524761]\n",
            "[17:01:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.09it/s, best loss: 0.414389483524761]\n",
            "[17:01:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.91it/s, best loss: 0.414389483524761]\n",
            "[17:01:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.58it/s, best loss: 0.414389483524761]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.86it/s, best loss: 0.414389483524761]\n",
            "[17:01:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.30it/s, best loss: 0.414389483524761]\n",
            "[17:01:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.18it/s, best loss: 0.414389483524761]\n",
            "[17:01:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.02it/s, best loss: 0.414389483524761]\n",
            "[17:01:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.81it/s, best loss: 0.414389483524761]\n",
            "[17:01:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.41it/s, best loss: 0.414389483524761]\n",
            "[17:01:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.28it/s, best loss: 0.414389483524761]\n",
            "[17:01:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.10it/s, best loss: 0.414389483524761]\n",
            "[17:01:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.80it/s, best loss: 0.414389483524761]\n",
            "[17:01:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.58it/s, best loss: 0.414389483524761]\n",
            "[17:01:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.79it/s, best loss: 0.4045300340032434]\n",
            "[17:01:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.64it/s, best loss: 0.4045300340032434]\n",
            "[17:01:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.53it/s, best loss: 0.4045300340032434]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.78it/s, best loss: 0.4045300340032434]\n",
            "[17:01:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.48it/s, best loss: 0.4045300340032434]\n",
            "[17:01:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.66it/s, best loss: 0.4045300340032434]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.44it/s, best loss: 0.4045300340032434]\n",
            "[17:01:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.31it/s, best loss: 0.4045300340032434]\n",
            "[17:01:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.31it/s, best loss: 0.4045300340032434]\n",
            "[17:01:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.05it/s, best loss: 0.4045300340032434]\n",
            "[17:01:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.56it/s, best loss: 0.4045300340032434]\n",
            "[17:01:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.66it/s, best loss: 0.4045300340032434]\n",
            "[17:01:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.92it/s, best loss: 0.4045300340032434]\n",
            "[17:01:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.41it/s, best loss: 0.4045300340032434]\n",
            "[17:01:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.68it/s, best loss: 0.4045300340032434]\n",
            "[17:01:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.76it/s, best loss: 0.4045300340032434]\n",
            "[17:01:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.10it/s, best loss: 0.3633865835461729]\n",
            "[17:01:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.69it/s, best loss: 0.3633865835461729]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.04it/s, best loss: 0.3633865835461729]\n",
            "[17:01:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.84it/s, best loss: 0.3633865835461729]\n",
            "[17:01:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.21it/s, best loss: 0.3633865835461729]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.12it/s, best loss: 0.3633865835461729]\n",
            "[17:01:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.81it/s, best loss: 0.3633865835461729]\n",
            "[17:01:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.05it/s, best loss: 0.3633865835461729]\n",
            "[17:01:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.10it/s, best loss: 0.3633865835461729]\n",
            "[17:01:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.52it/s, best loss: 0.3633865835461729]\n",
            "[17:01:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.37it/s, best loss: 0.3633865835461729]\n",
            "[17:01:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.00it/s, best loss: 0.3633865835461729]\n",
            "[17:01:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.41it/s, best loss: 0.3633865835461729]\n",
            "[17:01:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.96it/s, best loss: 0.3633865835461729]\n",
            "[17:01:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.73it/s, best loss: 0.3633865835461729]\n",
            "[17:01:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.01it/s, best loss: 0.3633865835461729]\n",
            "[17:01:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.61it/s, best loss: 0.3633865835461729]\n",
            "[17:01:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.36it/s, best loss: 0.3633865835461729]\n",
            "[17:01:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.96it/s, best loss: 0.3633865835461729]\n",
            "[17:01:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.66it/s, best loss: 0.3633865835461729]\n",
            "[17:01:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.84it/s, best loss: 0.3633865835461729]\n",
            "[17:01:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 13.55it/s, best loss: 0.3633865835461729]\n",
            "[17:01:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.94it/s, best loss: 0.3633865835461729]\n",
            "[17:01:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.67it/s, best loss: 0.3633865835461729]\n",
            "[17:01:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.82it/s, best loss: 0.3633865835461729]\n",
            "[17:01:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.86it/s, best loss: 0.3633865835461729]\n",
            "[17:01:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.50it/s, best loss: 0.3633865835461729]\n",
            "[17:01:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.63it/s, best loss: 0.3633865835461729]\n",
            "[17:01:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.15it/s, best loss: 0.3633865835461729]\n",
            "[17:01:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.55it/s, best loss: 0.3633865835461729]\n",
            "[17:01:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.13it/s, best loss: 0.3633865835461729]\n",
            "[17:01:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.41it/s, best loss: 0.3633865835461729]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 14.61it/s, best loss: 0.3633865835461729]\n",
            "[17:01:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.29it/s, best loss: 0.3633865835461729]\n",
            "[17:01:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.20it/s, best loss: 0.3633865835461729]\n",
            "[17:01:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.18it/s, best loss: 0.3633865835461729]\n",
            "[17:01:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.64it/s, best loss: 0.3633865835461729]\n",
            "[17:01:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.14it/s, best loss: 0.3633865835461729]\n",
            "[17:01:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.40it/s, best loss: 0.3633865835461729]\n",
            "[17:01:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.74it/s, best loss: 0.34607049660810274]\n",
            "[17:01:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.32it/s, best loss: 0.34607049660810274]\n",
            "[17:01:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.93it/s, best loss: 0.34607049660810274]\n",
            "[17:01:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.69it/s, best loss: 0.34607049660810274]\n",
            "[17:01:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.08it/s, best loss: 0.34607049660810274]\n",
            "[17:01:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.58it/s, best loss: 0.34607049660810274]\n",
            "[17:01:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.93it/s, best loss: 0.34607049660810274]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.15it/s, best loss: 0.34607049660810274]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 13.51it/s, best loss: 0.34607049660810274]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.18it/s, best loss: 0.34607049660810274]\n",
            "[17:01:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.93it/s, best loss: 0.34607049660810274]\n",
            "[17:01:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.83it/s, best loss: 0.34607049660810274]\n",
            "[17:01:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.24it/s, best loss: 0.34607049660810274]\n",
            "[17:01:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.88it/s, best loss: 0.34607049660810274]\n",
            "[17:01:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.61it/s, best loss: 0.34607049660810274]\n",
            "[17:01:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.99it/s, best loss: 0.34607049660810274]\n",
            "[17:01:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.61it/s, best loss: 0.34607049660810274]\n",
            "[17:01:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.81it/s, best loss: 0.34607049660810274]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.40it/s, best loss: 0.34607049660810274]\n",
            "[17:01:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.70it/s, best loss: 0.34607049660810274]\n",
            "[17:01:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.93it/s, best loss: 0.34607049660810274]\n",
            "[17:01:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.65it/s, best loss: 0.34607049660810274]\n",
            "[17:01:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.24it/s, best loss: 0.34607049660810274]\n",
            "[17:01:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.33it/s, best loss: 0.34607049660810274]\n",
            "[17:01:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.19it/s, best loss: 0.34607049660810274]\n",
            "[17:01:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.92it/s, best loss: 0.34607049660810274]\n",
            "[17:01:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.63it/s, best loss: 0.34607049660810274]\n",
            "[17:01:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 13.60it/s, best loss: 0.34607049660810274]\n",
            "[17:01:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.56it/s, best loss: 0.34607049660810274]\n",
            "[17:01:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.80it/s, best loss: 0.34607049660810274]\n",
            "[17:01:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.56it/s, best loss: 0.34607049660810274]\n",
            "[17:01:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.19it/s, best loss: 0.34607049660810274]\n",
            "[17:01:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.31it/s, best loss: 0.34607049660810274]\n",
            "[17:01:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.72it/s, best loss: 0.34607049660810274]\n",
            "[17:01:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.93it/s, best loss: 0.34607049660810274]\n",
            "[17:01:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.60it/s, best loss: 0.34607049660810274]\n",
            "[17:01:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.91it/s, best loss: 0.34607049660810274]\n",
            "[17:01:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.71it/s, best loss: 0.34607049660810274]\n",
            "[17:01:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.22it/s, best loss: 0.34607049660810274]\n",
            "[17:01:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.63it/s, best loss: 0.34607049660810274]\n",
            "[17:01:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.58it/s, best loss: 0.34607049660810274]\n",
            "[17:01:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.32it/s, best loss: 0.34607049660810274]\n",
            "[17:01:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.55it/s, best loss: 0.34607049660810274]\n",
            "[17:01:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.81it/s, best loss: 0.34607049660810274]\n",
            "[17:01:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.85it/s, best loss: 0.34607049660810274]\n",
            "[17:02:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.09it/s, best loss: 0.34607049660810274]\n",
            "[17:02:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.03it/s, best loss: 0.34607049660810274]\n",
            "[17:02:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.02it/s, best loss: 0.34607049660810274]\n",
            "[17:02:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.38it/s, best loss: 0.34607049660810274]\n",
            "[17:02:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.06it/s, best loss: 0.34607049660810274]\n",
            "[17:02:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.02it/s, best loss: 0.34607049660810274]\n",
            "[17:02:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.83it/s, best loss: 0.34607049660810274]\n",
            "[17:02:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.70it/s, best loss: 0.34607049660810274]\n",
            "[17:02:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.77it/s, best loss: 0.34607049660810274]\n",
            "[17:02:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.50it/s, best loss: 0.34607049660810274]\n",
            "[17:02:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.92it/s, best loss: 0.34607049660810274]\n",
            "[17:02:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.89it/s, best loss: 0.34607049660810274]\n",
            "[17:02:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.03it/s, best loss: 0.34607049660810274]\n",
            "[17:02:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.85it/s, best loss: 0.34607049660810274]\n",
            "[17:02:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.64it/s, best loss: 0.34607049660810274]\n",
            "[17:02:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.80it/s, best loss: 0.3418927547664157]\n",
            "[17:02:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.66it/s, best loss: 0.3418927547664157]\n",
            "[17:02:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.59it/s, best loss: 0.3418927547664157]\n",
            "[17:02:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.72it/s, best loss: 0.3418927547664157]\n",
            "[17:02:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.84it/s, best loss: 0.3418927547664157]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 15.13it/s, best loss: 0.3418927547664157]\n",
            "[17:02:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.68it/s, best loss: 0.3418927547664157]\n",
            "[17:02:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 13.63it/s, best loss: 0.3418927547664157]\n",
            "[17:02:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.83it/s, best loss: 0.3418927547664157]\n",
            "[17:02:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.09it/s, best loss: 0.3418927547664157]\n",
            "[17:02:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.02it/s, best loss: 0.3418927547664157]\n",
            "[17:02:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.77it/s, best loss: 0.3418927547664157]\n",
            "                                                   [17:02:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.24it/s, best loss: 0.3418927547664157]\n",
            "[17:02:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.00it/s, best loss: 0.3418927547664157]\n",
            "[17:02:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "0.0036916195241722184\n",
            "0.06075869916458234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu9N9zhM1qPx"
      },
      "source": [
        "*HyperoptEstimator* + cлучайный лес"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xakuZwY-tkJf",
        "outputId": "80e93b78-69de-4d4b-ba0b-4ecbe22c2fb2"
      },
      "source": [
        "from hpsklearn import HyperoptEstimator, xgboost_regression, random_forest_regression\n",
        "# # https://www.kaggle.com/ilialar/hyperparameters-tunning-with-hyperopt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "estim = HyperoptEstimator(regressor=random_forest_regression('my_gb'),\n",
        "                          max_evals=200, trial_timeout=10, seed=39,\n",
        "                          loss_fn=mean_squared_error)\n",
        "\n",
        "estim.fit(x_train_split, y_train_split)\n",
        "\n",
        "print(mean_squared_error(y_test_split, estim.predict(x_test_split)))\n",
        "print(math.sqrt(mean_squared_error(y_test_split, estim.predict(x_test_split))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.95it/s, best loss: 0.003593870789953797]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.22it/s, best loss: 0.003593870789953797]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.75s/it, best loss: 0.002978365714112272]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.37it/s, best loss: 0.002978365714112272]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.80it/s, best loss: 0.002978365714112272]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.25it/s, best loss: 0.002978365714112272]\n",
            "100%|██████████| 1/1 [00:00<00:00, 15.08it/s, best loss: 0.002445102978390254]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.74it/s, best loss: 0.002445102978390254]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.20s/it, best loss: 0.002445102978390254]\n",
            "100%|██████████| 1/1 [00:00<00:00, 13.88it/s, best loss: 0.002445102978390254]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.18s/it, best loss: 0.002445102978390254]\n",
            "100%|██████████| 1/1 [00:00<00:00, 15.09it/s, best loss: 0.002445102978390254]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.47it/s, best loss: 0.002445102978390254]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.40it/s, best loss: 0.002445102978390254]\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.72it/s, best loss: 0.002445102978390254]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.20it/s, best loss: 0.002445102978390254]\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.22it/s, best loss: 0.002445102978390254]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.39it/s, best loss: 0.002445102978390254]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.07it/s, best loss: 0.002445102978390254]\n",
            "100%|██████████| 1/1 [00:00<00:00, 13.42it/s, best loss: 0.002445102978390254]\n",
            "100%|██████████| 1/1 [00:00<00:00, 17.50it/s, best loss: 0.0022973828706808574]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.28it/s, best loss: 0.0022973828706808574]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.34it/s, best loss: 0.0022973828706808574]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.12it/s, best loss: 0.0021497822120030347]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.32s/it, best loss: 0.0021497822120030347]\n",
            "100%|██████████| 1/1 [00:00<00:00, 17.97it/s, best loss: 0.0021497822120030347]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.53it/s, best loss: 0.0021497822120030347]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.99it/s, best loss: 0.0021497822120030347]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.02it/s, best loss: 0.0021497822120030347]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.78s/it, best loss: 0.0021497822120030347]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.82it/s, best loss: 0.0021497822120030347]\n",
            "100%|██████████| 1/1 [00:00<00:00, 14.02it/s, best loss: 0.0021497822120030347]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.07it/s, best loss: 0.0021497822120030347]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.34s/it, best loss: 0.0021497822120030347]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.38s/it, best loss: 0.0021497822120030347]\n",
            "100%|██████████| 1/1 [00:00<00:00, 15.11it/s, best loss: 0.0021497822120030347]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.27it/s, best loss: 0.0021497822120030347]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.41it/s, best loss: 0.0021497822120030347]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.93it/s, best loss: 0.0019823777536337717]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.22it/s, best loss: 0.0019823777536337717]\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.15it/s, best loss: 0.0019823777536337717]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.06it/s, best loss: 0.0019823777536337717]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.81it/s, best loss: 0.0019823777536337717]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.82it/s, best loss: 0.0017965280500584794]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.06s/it, best loss: 0.0017965280500584794]\n",
            "100%|██████████| 1/1 [00:00<00:00, 13.46it/s, best loss: 0.0017965280500584794]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.11it/s, best loss: 0.0017965280500584794]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.93it/s, best loss: 0.0017965280500584794]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.07s/it, best loss: 0.0017965280500584794]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.66it/s, best loss: 0.0017965280500584794]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.75it/s, best loss: 0.0017965280500584794]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.68s/it, best loss: 0.0015453073698116467]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.01it/s, best loss: 0.0015453073698116467]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.45s/it, best loss: 0.0015453073698116467]\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.85it/s, best loss: 0.0015453073698116467]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.17it/s, best loss: 0.0015453073698116467]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.17it/s, best loss: 0.0015453073698116467]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.68s/it, best loss: 0.0015453073698116467]\n",
            "100%|██████████| 1/1 [00:00<00:00, 15.64it/s, best loss: 0.0015453073698116467]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.91s/it, best loss: 0.0015453073698116467]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.94s/it, best loss: 0.0015453073698116467]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.90it/s, best loss: 0.0015453073698116467]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.21s/it, best loss: 0.0015453073698116467]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.20it/s, best loss: 0.0015453073698116467]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.10it/s, best loss: 0.0015453073698116467]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.98it/s, best loss: 0.0015453073698116467]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.82s/it, best loss: 0.0015453073698116467]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.29it/s, best loss: 0.0015453073698116467]\n",
            "100%|██████████| 1/1 [00:00<00:00, 17.47it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.52it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 17.09it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.07it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 20.39it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.28s/it, best loss: 0.0011289957438238454]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.40it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.26it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.50it/s, best loss: 0.0011289957438238454]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.60it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.76it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.67it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.19s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.94it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.18it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.14it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.49it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.95it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.98it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.56s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.64it/s, best loss: 0.0011289957438238454]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.19it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 15.99it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.14it/s, best loss: 0.0011289957438238454]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.60it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.52s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 17.31it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.08it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.35s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.30it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.09it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.56s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.09it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.07it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.61it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.16s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.96it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 16.82it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.41s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.10it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 19.11it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.32it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.72it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.17it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.16s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.17s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.48s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.72it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 17.36it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.28s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 15.84it/s, best loss: 0.0011289957438238454]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.44it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.18it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.45it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.51s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 18.18it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 14.46it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 15.41it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.81it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.90it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.81it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.77it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.73it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.22it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 14.44it/s, best loss: 0.0011289957438238454]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.85it/s, best loss: 0.0011289957438238454]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.75it/s, best loss: 0.0011289957438238454]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.82it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.51it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.65it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.86it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 18.42it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 13.37it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.35it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.09it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 16.49it/s, best loss: 0.0011289957438238454]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.75it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.04it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.51it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 15.61it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.29s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 14.63it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 17.56it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.99it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.69it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.59it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.88s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 20.37it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.90it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.00it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.47s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.25s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 11.57it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.45it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 18.36it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 14.38it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.61it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.97s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.16it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.03it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 13.27it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 14.35it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 16.49it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.67it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 15.13it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.97it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.51it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.21it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.02s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.97it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.91it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.62s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.24s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 12.29it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.24it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.11it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.86s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.42it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.69it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 15.66it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.44it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.33s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.76it/s, best loss: 0.0011289957438238454]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_base.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X_transformed /= np.sqrt(self.explained_variance_)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Failing trial due to NaN in\n",
            "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=True)\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.97it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.03s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.27s/it, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.05it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.87it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 14.65it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.09it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00, 13.55it/s, best loss: 0.0011289957438238454]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.64it/s, best loss: 0.0011289957438238454]\n",
            "0.003840549986690327\n",
            "0.06197217106645794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv7D-gLI2dc2",
        "outputId": "8012167d-d1dd-48e4-90a0-811ec43e367d"
      },
      "source": [
        "  y_train_pred = estim.predict(x_train_split)\n",
        "  y_test_pred = estim.predict(x_test_split)\n",
        "\n",
        "  print('MSE train: {:.3f}, test: {:.3f}'.format(\n",
        "          mean_squared_error(y_train_split, y_train_pred),\n",
        "          mean_squared_error(y_test_split, y_test_pred)))\n",
        "  print('R^2 train: {:.3f}, test: {:.3f}'.format(\n",
        "          r2_score(y_train_split, y_train_pred),\n",
        "          r2_score(y_test_split, y_test_pred)))\n",
        "  print('RMSE train: {:.3f}, test: {:.3f}'.format(\n",
        "          math.sqrt(mean_squared_error(y_train_split, y_train_pred)),\n",
        "          math.sqrt(mean_squared_error(y_test_split, y_test_pred))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE train: 0.001, test: 0.004\n",
            "R^2 train: 0.891, test: 0.168\n",
            "RMSE train: 0.024, test: 0.062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px2EhlWj0i5V"
      },
      "source": [
        "# from hpsklearn import HyperoptEstimator, svc, knn, random_forest\n",
        "# from hyperopt import hp\n",
        "\n",
        "# clf = hp.choice('my_name',[random_forest('my_name.random_forest'),svc('my_name.svc'),knn('my_name.knn')])\n",
        "# estim = HyperoptEstimator(classifier=clf)\n",
        "\n",
        "# estim.fit(x_train_split.astype('float32'), y_train_split.astype('float32'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya39yBkk3u_j",
        "outputId": "10b868e4-8669-4c9a-acf2-814a2fb4627d"
      },
      "source": [
        "y_train_split"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.3054, 0.2766, 0.3769, 0.2963, 0.2865, 0.2543, 0.2674, 0.3248,\n",
              "       0.3869, 0.429 , 0.2719, 0.1974, 0.3333, 0.2454, 0.2775, 0.4268,\n",
              "       0.2287, 0.3801, 0.4   , 0.3894, 0.2762, 0.2628, 0.2778, 0.2778,\n",
              "       0.3791, 0.3533, 0.3661, 0.2519, 0.3452, 0.3402, 0.2795, 0.3636,\n",
              "       0.2909, 0.2584, 0.2092, 0.3431, 0.5625, 0.4289, 0.2682, 0.3388,\n",
              "       0.3775, 0.2137, 0.2517, 0.3201, 0.355 , 0.3973, 0.4562, 0.4099,\n",
              "       0.2766, 0.2918, 0.3579, 0.2895, 0.4239, 0.3299, 0.2189, 0.3074,\n",
              "       0.3125, 0.4436, 0.2562, 0.2419, 0.3774, 0.2171, 0.177 , 0.4488,\n",
              "       0.2386, 0.3901, 0.3835, 0.3375, 0.3941, 0.2371, 0.2251, 0.4419,\n",
              "       0.2851, 0.2463, 0.3624, 0.2979, 0.3205, 0.4381, 0.2637, 0.4356,\n",
              "       0.2347, 0.3391, 0.3421, 0.3081, 0.5   , 0.3667, 0.2659, 0.3162,\n",
              "       0.2653, 0.3568, 0.3486, 0.2696])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjnsVv2e3CO9",
        "outputId": "d8c7b950-3cc7-4ae3-ea42-4e7ae684dbfd"
      },
      "source": [
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from hpsklearn import HyperoptEstimator\n",
        "from hpsklearn import any_classifier\n",
        "from hpsklearn import any_preprocessing\n",
        "from hyperopt import tpe\n",
        "\n",
        "model = HyperoptEstimator(regressor=any_regressor('reg'), preprocessing=any_preprocessing('pre'), algo=tpe.suggest, max_evals=50, trial_timeout=30)\n",
        "# perform the search\n",
        "model.fit(x_train_split.values, y_train_split.values)\n",
        "# summarize performance\n",
        "acc = model.score(x_test_split, y_test_split)\n",
        "print(\"Accuracy: %.3f\" % acc)\n",
        "# summarize the best model\n",
        "print(model.best_model())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.76it/s, best loss: 1.0055132873395893]\n",
            "[12:19:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.44it/s, best loss: 1.0055132873395893]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.94it/s, best loss: 0.655334480764773]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.46it/s, best loss: 0.655334480764773]\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.10it/s, best loss: 0.655334480764773]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.12it/s, best loss: 0.655334480764773]\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.17it/s, best loss: 0.655334480764773]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.99it/s, best loss: 0.655334480764773]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.03s/it, best loss: 0.655334480764773]\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.19it/s, best loss: 0.655334480764773]\n",
            "[12:19:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.86it/s, best loss: 0.655334480764773]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.43it/s, best loss: 0.655334480764773]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.42it/s, best loss: 0.48825253367837307]\n",
            "[12:19:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.71it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.07s/it, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.03it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.73it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.42s/it, best loss: 0.48825253367837307]\n",
            "[12:19:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.39it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.82it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.33it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.41it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.53it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.92it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.34it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.27it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.05it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.50it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.81it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.17it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.78it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.29it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.87s/it, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.57it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.16it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.42it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.87it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.16it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.29it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.18it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.01it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.39it/s, best loss: 0.48825253367837307]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.10it/s, best loss: 0.44193632620972023]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.47it/s, best loss: 0.44193632620972023]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.10s/it, best loss: 0.44193632620972023]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.41s/it, best loss: 0.44193632620972023]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.22it/s, best loss: 0.44193632620972023]\n",
            "[12:19:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.05it/s, best loss: 0.44193632620972023]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.99it/s, best loss: 0.44193632620972023]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.22it/s, best loss: 0.44193632620972023]\n",
            "Accuracy: 0.132\n",
            "{'learner': RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
            "                      max_depth=4, max_features=None, max_leaf_nodes=None,\n",
            "                      max_samples=None, min_impurity_decrease=0.0,\n",
            "                      min_impurity_split=None, min_samples_leaf=2,\n",
            "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                      n_estimators=14, n_jobs=1, oob_score=False,\n",
            "                      random_state=4, verbose=False, warm_start=False), 'preprocs': (PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
            "    svd_solver='auto', tol=0.0, whiten=False),), 'ex_preprocs': ()}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uodYSS9gTCSe"
      },
      "source": [
        "# Вывод в файл"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ6pBwh1uDO0"
      },
      "source": [
        "1. Прямой АДбуст"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3_GkZQct4Hv"
      },
      "source": [
        "df_work = pd.read_csv(\"Empty_part.csv\")\r\n",
        "df_train = pd.read_csv(\"Training_wells.csv\")\r\n",
        "\r\n",
        "x_for_predict = df_work[['X','Y']]\r\n",
        "\r\n",
        "y_trainig = df_train[\"NTG\"] \r\n",
        "x_training = df_train[['X','Y']]\r\n",
        "x_for_predict\r\n",
        "regr = AdaBoostRegressor(base_estimator=None, learning_rate=1.6273721018635237,\r\n",
        "                  loss='linear', n_estimators=35, random_state=2100)\r\n",
        "regr.fit(x_training, y_trainig)\r\n",
        "\r\n",
        "y_answ = regr.predict(x_for_predict)\r\n",
        "len(y_answ)\r\n",
        "\r\n",
        "df_work[\"NTG\"] = y_answ.round(4)\r\n",
        "df_work\r\n",
        "df_work.to_csv('2.AdaBopst_3.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cePFa6GR7gEf"
      },
      "source": [
        "Случайный лес"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB0F5rJW7hBH"
      },
      "source": [
        "df_work = pd.read_csv(\"Empty_part.csv\")\r\n",
        "df_train = pd.read_csv(\"Training_wells.csv\")\r\n",
        "\r\n",
        "x_for_predict = df_work[['X','Y']]\r\n",
        "\r\n",
        "y_trainig = df_train[\"NTG\"] \r\n",
        "x_training = df_train[['X','Y']]\r\n",
        "x_for_predict\r\n",
        "\r\n",
        "\r\n",
        "poly_reg = PolynomialFeatures(degree=8)\r\n",
        "x_training  = poly_reg.fit_transform(x_training)\r\n",
        "x_for_predict = poly_reg.fit_transform(x_for_predict)\r\n",
        "\r\n",
        "\r\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\r\n",
        "x_training = scaler.fit_transform(x_training)\r\n",
        "x_for_predict = scaler.transform(x_for_predict)\r\n",
        "\r\n",
        "model = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\r\n",
        "                      max_depth=20, max_features='sqrt', max_leaf_nodes=None,\r\n",
        "                      max_samples=None, min_impurity_decrease=0.0,\r\n",
        "                      min_impurity_split=None, min_samples_leaf=2,\r\n",
        "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\r\n",
        "                      n_estimators=250, n_jobs=None, oob_score=False,\r\n",
        "                      random_state=30, verbose=0, warm_start=False)\r\n",
        "\r\n",
        "model.fit(x_training,y_trainig)\r\n",
        "\r\n",
        "\r\n",
        "y_answ = model.predict(x_for_predict)\r\n",
        "len(y_answ)\r\n",
        "\r\n",
        "df_work[\"NTG\"] = y_answ.round(4)\r\n",
        "df_work\r\n",
        "df_work.to_csv('4.Fores_scale_poly.csv', index = False)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3Vf6Que-9-H"
      },
      "source": [
        "*Голосование* 3х улгоритмов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UWWj1uI_BFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b9267e59-a7b9-4671-e3bd-5158f3ea5950"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\r\n",
        "from sklearn.datasets import make_regression\r\n",
        "from hpsklearn import ada_boost_regression, extra_trees_regression, svr_poly, \\\r\n",
        "svr, svr_linear, svr_rbf, svr_poly, svr_sigmoid, knn_regression, sgd_regression, gradient_boosting_regression, \\\r\n",
        "random_forest_regression, extra_trees_regression, sgd_regression, xgboost_regression\r\n",
        "from sklearn.metrics import max_error, mean_squared_log_error\r\n",
        "from sklearn.svm import SVR\r\n",
        "from sklearn.svm import LinearSVR\r\n",
        "\r\n",
        "# разделим выборку на тест и обучение \r\n",
        "\r\n",
        "df_work = pd.read_csv(\"Empty_part.csv\")\r\n",
        "df_train = pd.read_csv(\"Training_wells.csv\")\r\n",
        "\r\n",
        "x_for_predict = df_work[['X','Y']]\r\n",
        "\r\n",
        "y_trainig = df_train[\"NTG\"] \r\n",
        "x_training = df_train[['X','Y']]\r\n",
        "x_for_predict\r\n",
        "\r\n",
        "\r\n",
        "poly_reg = PolynomialFeatures(degree=5)\r\n",
        "x_training  = poly_reg.fit_transform(x_training)\r\n",
        "x_for_predict = poly_reg.fit_transform(x_for_predict)\r\n",
        "\r\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\r\n",
        "x_training = scaler.fit_transform(x_training)\r\n",
        "x_for_predict = scaler.transform(x_for_predict)\r\n",
        "\r\n",
        "\r\n",
        "regr = AdaBoostRegressor(base_estimator=None, learning_rate=1.6273721018635237,\r\n",
        "                  loss='linear', n_estimators=35, random_state=2100)\r\n",
        "\r\n",
        "regr.fit(x_training, y_trainig)\r\n",
        "y_for_predict = regr.predict(x_for_predict)\r\n",
        "\r\n",
        "################################3\r\n",
        "# model = estim = HyperoptEstimator(regressor=svr_linear('my_gb'),\r\n",
        "#                         max_evals=10, trial_timeout=10, seed=39,\r\n",
        "#                         loss_fn=mean_squared_error)\r\n",
        "\r\n",
        "model = SVR(C=0.00011055634849084026, cache_size=512, coef0=0.0, degree=1,\r\n",
        "    epsilon=0.001115347080173807, gamma='auto', kernel='linear',\r\n",
        "    max_iter=170274026.0, shrinking=False, tol=0.0002988612959169446,\r\n",
        "    verbose=False)\r\n",
        "\r\n",
        "\r\n",
        "model.fit(x_training, y_trainig)\r\n",
        "y_for_predict_2 = model.predict(x_for_predict)\r\n",
        "\r\n",
        "###################################\r\n",
        "# estim = HyperoptEstimator(regressor=ada_boost_regression('my_gb'),\r\n",
        "#                         max_evals=10, trial_timeout=10, seed=39,\r\n",
        "#                         loss_fn=mean_squared_error)\r\n",
        "estim = AdaBoostRegressor(base_estimator=None, learning_rate=0.19877223857045706,\r\n",
        "                  loss='square', n_estimators=285, random_state=3)\r\n",
        "\r\n",
        "estim.fit(x_training, y_trainig)\r\n",
        "y_for_predict_3 = estim.predict(x_for_predict)\r\n",
        "\r\n",
        "A = 0.5\r\n",
        "B = 0.25\r\n",
        "C = 1 - A - B\r\n",
        "y_answ = A*y_for_predict + + B*y_for_predict_2 + C*y_for_predict_3\r\n",
        "\r\n",
        "len(y_answ)\r\n",
        "\r\n",
        "df_work[\"NTG\"] = y_answ.round(4)\r\n",
        "df_work\r\n",
        "df_work.to_csv('5.3_algo_NOT_FAKE_LinearSVR.csv', index = False)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-f8905fa75614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001115347080173807\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m170274026.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0002988612959169446\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     verbose=False)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'cache_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rU-kmi4NHPI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyEpP0rbbJFY"
      },
      "source": [
        "Чистая полиномиальная регрессия"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_2O03pdaiFK"
      },
      "source": [
        "df_work = pd.read_csv(\"Empty_part.csv\")\r\n",
        "df_train = pd.read_csv(\"Training_wells.csv\")\r\n",
        "\r\n",
        "x_for_predict = df_work[['X','Y']]\r\n",
        "\r\n",
        "y_trainig = df_train[\"NTG\"] \r\n",
        "x_training = df_train[['X','Y']]\r\n",
        "x_for_predict\r\n",
        "\r\n",
        "\r\n",
        "poly_reg = PolynomialFeatures(degree=5)\r\n",
        "x_training  = poly_reg.fit_transform(x_training)\r\n",
        "x_for_predict = poly_reg.fit_transform(x_for_predict)\r\n",
        "\r\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\r\n",
        "x_training = scaler.fit_transform(x_training)\r\n",
        "x_for_predict = scaler.transform(x_for_predict)\r\n",
        "\r\n",
        "model_answ = LinearRegression()\r\n",
        "model_answ.fit(x_training, y_trainig)\r\n",
        "\r\n",
        "estim.fit(x_training, y_trainig)\r\n",
        "y_answ = model_answ.predict(x_for_predict)\r\n",
        "len(y_answ)\r\n",
        "\r\n",
        "df_work[\"NTG\"] = y_answ.round(4)\r\n",
        "df_work\r\n",
        "df_work.to_csv('6. Polinom.csv', index = False)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk0E_O3FvdFh"
      },
      "source": [
        "# Попробуем класификацией"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPfemJThWWB_"
      },
      "source": [
        "### Передалаем ответа на 5 классов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrsNKBA2vdFi",
        "outputId": "43bc39d6-6bb6-4776-c447-3d1676a7048d"
      },
      "source": [
        "# давай разедилм данные на класс и попробуем класификатор\n",
        "# разбиил на 5 классов \n",
        "df_12 = df_train.copy()\n",
        "\n",
        "df_12.loc[(df_12['NTG'] >= 0.1) & (df_12['NTG'] < 0.2), 'NTG'] = 1 # 0.2\n",
        "df_12.loc[(df_12['NTG'] >= 0.2) & (df_12['NTG'] < 0.3), 'NTG'] = 2 # 0.3\n",
        "df_12.loc[(df_12['NTG'] >= 0.3) & (df_12['NTG'] < 0.4), 'NTG'] = 3 # 0.4\n",
        "df_12.loc[(df_12['NTG'] >= 0.4) & (df_12['NTG'] < 0.5), 'NTG'] = 4 # 0.5\n",
        "df_12.loc[(df_12['NTG'] >= 0.5) & (df_12['NTG'] < 0.6), 'NTG'] = 5 # 0.6\n",
        "\n",
        "df_12\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Well</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>NTG</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>201-907</td>\n",
              "      <td>201</td>\n",
              "      <td>907</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>201-914</td>\n",
              "      <td>201</td>\n",
              "      <td>914</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>201-924</td>\n",
              "      <td>201</td>\n",
              "      <td>924</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>202-922</td>\n",
              "      <td>202</td>\n",
              "      <td>922</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>202-925</td>\n",
              "      <td>202</td>\n",
              "      <td>925</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>245-908</td>\n",
              "      <td>245</td>\n",
              "      <td>908</td>\n",
              "      <td>2.0</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>245-911</td>\n",
              "      <td>245</td>\n",
              "      <td>911</td>\n",
              "      <td>3.0</td>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>245-923</td>\n",
              "      <td>245</td>\n",
              "      <td>923</td>\n",
              "      <td>4.0</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>246-905</td>\n",
              "      <td>246</td>\n",
              "      <td>905</td>\n",
              "      <td>4.0</td>\n",
              "      <td>136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>246-923</td>\n",
              "      <td>246</td>\n",
              "      <td>923</td>\n",
              "      <td>3.0</td>\n",
              "      <td>137</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>138 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Well    X    Y  NTG  index\n",
              "0    201-907  201  907  2.0      0\n",
              "1    201-914  201  914  3.0      1\n",
              "2    201-924  201  924  4.0      2\n",
              "3    202-922  202  922  4.0      3\n",
              "4    202-925  202  925  4.0      4\n",
              "..       ...  ...  ...  ...    ...\n",
              "133  245-908  245  908  2.0    133\n",
              "134  245-911  245  911  3.0    134\n",
              "135  245-923  245  923  4.0    135\n",
              "136  246-905  246  905  4.0    136\n",
              "137  246-923  246  923  3.0    137\n",
              "\n",
              "[138 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2hdC18-Wh7Z"
      },
      "source": [
        "### Передалаем ответа на 12 классов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "KNM-1p3RvdFi",
        "outputId": "23af556a-90ed-40a1-8d66-ba6f9b547953"
      },
      "source": [
        "# оразбили на 12 классов \n",
        "df_12 = df_train.copy()\n",
        "\n",
        "# прямой переход\n",
        "df_12.loc[(df_12['NTG'] >= 0.1) & (df_12['NTG'] < 0.15), 'NTG'] = 1 # 0.15\n",
        "df_12.loc[(df_12['NTG'] >= 0.15) & (df_12['NTG'] < 0.2), 'NTG'] = 2 # 0.2\n",
        "df_12.loc[(df_12['NTG'] >= 0.2) & (df_12['NTG'] < 0.25), 'NTG'] = 3 # 0.25\n",
        "df_12.loc[(df_12['NTG'] >= 0.25) & (df_12['NTG'] < 0.3), 'NTG'] = 4 # 0.3\n",
        "df_12.loc[(df_12['NTG'] >= 0.3) & (df_12['NTG'] < 0.35), 'NTG'] = 5 # 0.35\n",
        "df_12.loc[(df_12['NTG'] >= 0.35) & (df_12['NTG'] < 0.5), 'NTG'] = 6 # 0.4\n",
        "df_12.loc[(df_12['NTG'] >= 0.4) & (df_12['NTG'] < 0.45), 'NTG'] = 7 # 0.45\n",
        "df_12.loc[(df_12['NTG'] >= 0.45) & (df_12['NTG'] < 0.5), 'NTG'] = 8 # 0.5\n",
        "df_12.loc[(df_12['NTG'] >= 0.5) & (df_12['NTG'] < 0.55), 'NTG'] = 9 # 0.55\n",
        "df_12.loc[(df_12['NTG'] >= 0.55) & (df_12['NTG'] <= 0.6), 'NTG'] = 10 # 0.6\n",
        "\n",
        "df_12.head(3)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Well</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>NTG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>201-907</td>\n",
              "      <td>201</td>\n",
              "      <td>907</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>201-914</td>\n",
              "      <td>201</td>\n",
              "      <td>914</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>201-924</td>\n",
              "      <td>201</td>\n",
              "      <td>924</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Well    X    Y  NTG\n",
              "0  201-907  201  907  3.0\n",
              "1  201-914  201  914  6.0\n",
              "2  201-924  201  924  6.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pjNSGaHY7kY",
        "outputId": "33daae86-59a7-4180-c8d7-5d410eb8f6e1"
      },
      "source": [
        "# обратный переход\r\n",
        "\r\n",
        "return_dict    = {1:0.15,\r\n",
        "                  2:0.2,\r\n",
        "                  3:0.25,\r\n",
        "                  4:0.3,\r\n",
        "                  5:0.35,\r\n",
        "                  6:0.40,\r\n",
        "                  7:0.45,\r\n",
        "                  8:0.5,\r\n",
        "                  9:0.55,\r\n",
        "                  10:0.6,\r\n",
        "                  }\r\n",
        "\r\n",
        "def return_from_12(y_12):\r\n",
        "  y_norm = np.zeros(len(y_12))\r\n",
        "  for i, y in enumerate(y_12):\r\n",
        "    y_norm[i] = return_dict[y]\r\n",
        "  return y_norm\r\n",
        "  \r\n",
        "return_from_12(df_12['NTG'].to_list())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.25, 0.4 , 0.4 , 0.4 , 0.4 , 0.3 , 0.3 , 0.35, 0.25, 0.2 , 0.4 ,\n",
              "       0.35, 0.35, 0.35, 0.4 , 0.35, 0.35, 0.3 , 0.2 , 0.35, 0.3 , 0.35,\n",
              "       0.3 , 0.3 , 0.4 , 0.3 , 0.35, 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 ,\n",
              "       0.35, 0.4 , 0.4 , 0.35, 0.25, 0.35, 0.4 , 0.35, 0.35, 0.4 , 0.35,\n",
              "       0.3 , 0.4 , 0.3 , 0.35, 0.25, 0.4 , 0.4 , 0.3 , 0.3 , 0.3 , 0.4 ,\n",
              "       0.3 , 0.4 , 0.4 , 0.4 , 0.35, 0.3 , 0.3 , 0.25, 0.4 , 0.25, 0.4 ,\n",
              "       0.4 , 0.4 , 0.4 , 0.4 , 0.3 , 0.35, 0.4 , 0.35, 0.35, 0.25, 0.3 ,\n",
              "       0.3 , 0.3 , 0.35, 0.35, 0.4 , 0.4 , 0.3 , 0.4 , 0.35, 0.4 , 0.35,\n",
              "       0.4 , 0.4 , 0.3 , 0.35, 0.35, 0.35, 0.35, 0.3 , 0.3 , 0.4 , 0.3 ,\n",
              "       0.25, 0.6 , 0.3 , 0.3 , 0.4 , 0.25, 0.25, 0.3 , 0.3 , 0.4 , 0.25,\n",
              "       0.25, 0.4 , 0.25, 0.25, 0.4 , 0.3 , 0.35, 0.35, 0.25, 0.3 , 0.25,\n",
              "       0.55, 0.2 , 0.4 , 0.2 , 0.3 , 0.4 , 0.4 , 0.25, 0.3 , 0.3 , 0.4 ,\n",
              "       0.4 , 0.3 , 0.4 , 0.4 , 0.4 , 0.4 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_9N4AI6b1la"
      },
      "source": [
        "x_train_12 = df_12[['X','Y']]\r\n",
        "y_train_12 = df_12['NTG']\r\n",
        "x_train_split_12, x_test_split_12, y_train_split_12, y_test_split_12 = train_test_split(x_train_12, y_train_12, \r\n",
        "                                                                                       test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANgJaf5qbcDz",
        "outputId": "3b46a2e4-3e28-4825-8ceb-91db0669ec46"
      },
      "source": [
        "\r\n",
        "model = GradientBoostingClassifier(n_estimators=60, \r\n",
        "                                  max_depth = 3, \r\n",
        "                                  max_features = 'sqrt', \r\n",
        "                                  min_samples_leaf = 2, \r\n",
        "                                  random_state=42)\r\n",
        "\r\n",
        "# define the ovr strategy\r\n",
        "ovr = OneVsOneClassifier(model)\r\n",
        "\r\n",
        "# fit model\r\n",
        "ovr.fit(x_train_split_12, y_train_split_12)\r\n",
        "\r\n",
        "# make predictions\r\n",
        "y_test_pred = ovr.predict(x_test_split_12)\r\n",
        "\r\n",
        "# #   проверка качества по кросс валедации\r\n",
        "acc = accuracy_score(y_test_pred, y_test_split_12)\r\n",
        "print(acc)\r\n",
        "\r\n",
        "y_test_pred = return_from_12(ovr.predict(x_test_split_12))\r\n",
        "\r\n",
        "print('RMSE ', math.sqrt(mean_squared_error(y_test_split, y_test_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.45652173913043476\n",
            "RMSE  33.30607171438083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "7EnZmXds0OzV",
        "outputId": "f4f239c3-375a-4dde-8c41-e43db1b7a4ef"
      },
      "source": [
        "# а теперь разобьем по линиям У\r\n",
        "df_train = pd.read_csv(\"Training_wells.csv\")\r\n",
        "\r\n",
        "dict_for_y = dict() # для обратного перехода\r\n",
        "for i,y in enumerate(set(df_train['Y'].to_list())): \r\n",
        "  # print(i+1)\r\n",
        "  dict_for_y[y] = df_train['X'] #запищем Х # классы начинаюстя с 1го\r\n",
        "  df_train.loc[df_train['Y'] == y, 'NTG'] = i+1\r\n",
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Well</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>NTG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>201-907</td>\n",
              "      <td>201</td>\n",
              "      <td>907</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>201-914</td>\n",
              "      <td>201</td>\n",
              "      <td>914</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>201-924</td>\n",
              "      <td>201</td>\n",
              "      <td>924</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>202-922</td>\n",
              "      <td>202</td>\n",
              "      <td>922</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>202-925</td>\n",
              "      <td>202</td>\n",
              "      <td>925</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>245-908</td>\n",
              "      <td>245</td>\n",
              "      <td>908</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>245-911</td>\n",
              "      <td>245</td>\n",
              "      <td>911</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>245-923</td>\n",
              "      <td>245</td>\n",
              "      <td>923</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>246-905</td>\n",
              "      <td>246</td>\n",
              "      <td>905</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>246-923</td>\n",
              "      <td>246</td>\n",
              "      <td>923</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>138 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Well    X    Y   NTG\n",
              "0    201-907  201  907   7.0\n",
              "1    201-914  201  914  14.0\n",
              "2    201-924  201  924  24.0\n",
              "3    202-922  202  922  22.0\n",
              "4    202-925  202  925  25.0\n",
              "..       ...  ...  ...   ...\n",
              "133  245-908  245  908   8.0\n",
              "134  245-911  245  911  11.0\n",
              "135  245-923  245  923  23.0\n",
              "136  246-905  246  905   5.0\n",
              "137  246-923  246  923  23.0\n",
              "\n",
              "[138 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TEYG95by1Dr"
      },
      "source": [
        "x_train = df_train[['X','Y']]\r\n",
        "y_train = df_train['NTG']\r\n",
        "x_train_split, x_test_split, y_train_split, y_test_split = train_test_split(x_train, y_train, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h_AP0hb1iFR",
        "outputId": "f23448cc-a62c-4f4e-b065-64b2a10a8659"
      },
      "source": [
        "y_train_split"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15     12.0\n",
              "119    21.0\n",
              "39      4.0\n",
              "22     27.0\n",
              "55     29.0\n",
              "       ... \n",
              "71      7.0\n",
              "106    20.0\n",
              "14     27.0\n",
              "92     20.0\n",
              "102    24.0\n",
              "Name: NTG, Length: 92, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io0Jn8cwvdFj"
      },
      "source": [
        "### СВЕДЕМ ЗАДАЧУ КЛАССИФИКАЦИИ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejmB1-WPvdFj"
      },
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTDinOJbvdFj"
      },
      "source": [
        "def grad_bust_class():\n",
        "\n",
        "  model = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "  # define the ovr strategy\n",
        "  ovr = OneVsRestClassifier(model)\n",
        "\n",
        "  # fit model\n",
        "  ovr.fit(x_train_split, y_train_split)\n",
        "\n",
        "  # make predictions\n",
        "  y_test_pred = ovr.predict(x_test_split)\n",
        "  y_train_pred = ovr.predict(x_train_split)\n",
        "\n",
        "\n",
        "  print('accuracy_score train: {:.3f}, test: {:.3f}'.format(\n",
        "          accuracy_score(y_train_split, y_train_pred),\n",
        "          accuracy_score(y_test_split, y_test_pred)))\n",
        "  \n",
        "grad_bust_class()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJLy5nHjvdFk"
      },
      "source": [
        "### Подберем параметры по сетке"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEakmXZOvdFl"
      },
      "source": [
        "# параметры которые будем подбирать\n",
        "\n",
        "# Loss function to be optimized\n",
        "loss = ['lad', 'huber']\n",
        "\n",
        "# Number of trees used in the boosting process\n",
        "n_estimators = [60, 80, 100, 120]\n",
        "\n",
        "# Maximum depth of each tree\n",
        "max_depth = [2, 3, 5, 10, 15]\n",
        "\n",
        "# Minimum number of samples per leaf\n",
        "min_samples_leaf = [1, 2, 4, 6, 8]\n",
        "\n",
        "# Minimum number of samples to split a node\n",
        "min_samples_split = [2, 4, 6, 10]\n",
        "\n",
        "# Maximum number of features to consider for making splits\n",
        "max_features = ['auto', 'sqrt', 'log2', None]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "Mzpho8syvdFl",
        "outputId": "22acebd1-5a9d-407b-ce19-70a418c6edff"
      },
      "source": [
        "# подбор параметрво по сетке\n",
        "\n",
        "acc_score = pd.DataFrame()\n",
        "\n",
        "list_n_estimators = []\n",
        "list_max_depth = []\n",
        "list_acc_score = []\n",
        "list_min_samples_leaf = []\n",
        "list_max_features = []\n",
        "         \n",
        "\n",
        "\n",
        "for n_est in n_estimators :\n",
        "    for max_d in max_depth :\n",
        "        for max_f in max_features :\n",
        "            for min_leaf in min_samples_leaf :\n",
        "                \n",
        "                list_n_estimators.append(n_est)\n",
        "                list_max_depth.append(max_d)\n",
        "                list_max_features.append(max_f)\n",
        "                list_min_samples_leaf.append(min_leaf)\n",
        "\n",
        "                # define model\n",
        "                model = GradientBoostingClassifier(n_estimators=n_est, \n",
        "                                                   max_depth = max_d, \n",
        "                                                   max_features = max_f, \n",
        "                                                   min_samples_leaf = min_leaf, \n",
        "#                                                    min_samples_split = min_split,\n",
        "#                                                    loss = lo,\n",
        "                                                   random_state=42)\n",
        "\n",
        "                # define the ovr strategy\n",
        "                ovr = OneVsRestClassifier(model)\n",
        "\n",
        "                # fit model\n",
        "                ovr.fit(x_train_split, y_train_split_12)\n",
        "\n",
        "                # make predictions\n",
        "                y_test_pred = ovr.predict(x_test_split_12)\n",
        "\n",
        "                # #   проверка качества по кросс валедации\n",
        "                acc = accuracy_score(y_test_split_12, y_test_pred)\n",
        "\n",
        "                list_acc_score.append(acc)\n",
        "\n",
        "acc_score[\"acc_scire\"] = list_acc_score        \n",
        "acc_score[\"n_estimators\"] = list_n_estimators\n",
        "acc_score[\"max_depth\"] = list_max_depth\n",
        "acc_score[\"max_features\"] = list_max_features\n",
        "acc_score[\"min_samples_leaf\"] = list_min_samples_leaf\n",
        "\n",
        "acc_score.sort_values(by = 'acc_scire', ascending = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc_scire</th>\n",
              "      <th>n_estimators</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>max_features</th>\n",
              "      <th>min_samples_leaf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>0.478261</td>\n",
              "      <td>80</td>\n",
              "      <td>5</td>\n",
              "      <td>log2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>0.478261</td>\n",
              "      <td>100</td>\n",
              "      <td>15</td>\n",
              "      <td>auto</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>0.478261</td>\n",
              "      <td>80</td>\n",
              "      <td>15</td>\n",
              "      <td>auto</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>0.478261</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>auto</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>0.478261</td>\n",
              "      <td>80</td>\n",
              "      <td>15</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>0.347826</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>0.347826</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>0.347826</td>\n",
              "      <td>120</td>\n",
              "      <td>3</td>\n",
              "      <td>auto</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>0.347826</td>\n",
              "      <td>120</td>\n",
              "      <td>3</td>\n",
              "      <td>auto</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.347826</td>\n",
              "      <td>60</td>\n",
              "      <td>2</td>\n",
              "      <td>auto</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     acc_scire  n_estimators  max_depth max_features  min_samples_leaf\n",
              "151   0.478261            80          5         log2                 2\n",
              "280   0.478261           100         15         auto                 1\n",
              "180   0.478261            80         15         auto                 1\n",
              "222   0.478261           100          3         auto                 4\n",
              "195   0.478261            80         15         None                 1\n",
              "..         ...           ...        ...          ...               ...\n",
              "235   0.347826           100          3         None                 1\n",
              "236   0.347826           100          3         None                 2\n",
              "320   0.347826           120          3         auto                 1\n",
              "321   0.347826           120          3         auto                 2\n",
              "0     0.347826            60          2         auto                 1\n",
              "\n",
              "[400 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LV-tUQ7avdFm"
      },
      "source": [
        "### Многоклассовая One-Vs-One - с GradBust"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o58Zu7XcvdFn",
        "scrolled": true
      },
      "source": [
        "# подбор параметрво по сетке\n",
        "\n",
        "acc_score_2 = pd.DataFrame()\n",
        "\n",
        "list_n_estimators = []\n",
        "list_max_depth = []\n",
        "list_acc_score = []\n",
        "list_min_samples_leaf = []\n",
        "list_max_features = []\n",
        "         \n",
        "\n",
        "\n",
        "for n_est in n_estimators :\n",
        "    for max_d in max_depth :\n",
        "        for max_f in max_features :\n",
        "            for min_leaf in min_samples_leaf :\n",
        "                \n",
        "                list_n_estimators.append(n_est)\n",
        "                list_max_depth.append(max_d)\n",
        "                list_max_features.append(max_f)\n",
        "                list_min_samples_leaf.append(min_leaf)\n",
        "\n",
        "                # define model\n",
        "                model = GradientBoostingClassifier(n_estimators=n_est, \n",
        "                                                   max_depth = max_d, \n",
        "                                                   max_features = max_f, \n",
        "                                                   min_samples_leaf = min_leaf, \n",
        "#                                                    min_samples_split = min_split,\n",
        "#                                                    loss = lo,\n",
        "                                                   random_state=42)\n",
        "\n",
        "                # define the ovr strategy\n",
        "                ovr = OneVsOneClassifier(model)\n",
        "\n",
        "                # fit model\n",
        "                ovr.fit(x_train_split_12, y_train_split_12)\n",
        "\n",
        "                # make predictions\n",
        "                y_test_pred = ovr.predict(x_test_split_12)\n",
        "\n",
        "                # #   проверка качества по кросс валедации\n",
        "                acc = accuracy_score(y_test_pred, y_test_split_12)\n",
        "\n",
        "                list_acc_score.append(acc)\n",
        "\n",
        "acc_score_2[\"acc_scire\"] = list_acc_score        \n",
        "acc_score_2[\"n_estimators\"] = list_n_estimators\n",
        "acc_score_2[\"max_depth\"] = list_max_depth\n",
        "acc_score_2[\"max_features\"] = list_max_features\n",
        "acc_score_2[\"min_samples_leaf\"] = list_min_samples_leaf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "3SVNfnolvdFn",
        "scrolled": true,
        "outputId": "4470f2ec-277e-4217-8646-760bb9d11a19"
      },
      "source": [
        "acc_score_2.sort_values(by = 'acc_scire', ascending = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc_scire</th>\n",
              "      <th>n_estimators</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>max_features</th>\n",
              "      <th>min_samples_leaf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>0.478261</td>\n",
              "      <td>80</td>\n",
              "      <td>5</td>\n",
              "      <td>log2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>0.478261</td>\n",
              "      <td>120</td>\n",
              "      <td>2</td>\n",
              "      <td>auto</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>0.478261</td>\n",
              "      <td>120</td>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0.478261</td>\n",
              "      <td>60</td>\n",
              "      <td>5</td>\n",
              "      <td>log2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.478261</td>\n",
              "      <td>60</td>\n",
              "      <td>5</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.304348</td>\n",
              "      <td>60</td>\n",
              "      <td>5</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>0.282609</td>\n",
              "      <td>60</td>\n",
              "      <td>10</td>\n",
              "      <td>log2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>0.282609</td>\n",
              "      <td>60</td>\n",
              "      <td>10</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>0.282609</td>\n",
              "      <td>60</td>\n",
              "      <td>15</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>0.282609</td>\n",
              "      <td>60</td>\n",
              "      <td>15</td>\n",
              "      <td>log2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     acc_scire  n_estimators  max_depth max_features  min_samples_leaf\n",
              "150   0.478261            80          5         log2                 1\n",
              "301   0.478261           120          2         auto                 2\n",
              "316   0.478261           120          2         None                 2\n",
              "50    0.478261            60          5         log2                 1\n",
              "45    0.478261            60          5         sqrt                 1\n",
              "..         ...           ...        ...          ...               ...\n",
              "48    0.304348            60          5         sqrt                 6\n",
              "73    0.282609            60         10         log2                 6\n",
              "68    0.282609            60         10         sqrt                 6\n",
              "88    0.282609            60         15         sqrt                 6\n",
              "93    0.282609            60         15         log2                 6\n",
              "\n",
              "[400 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7J-BrM-vdFn"
      },
      "source": [
        "### Многоклассовая One-Vs-Rest - SVM - работает оч долго, поэтому писал свой"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF68Do02vdFo"
      },
      "source": [
        "# параметры подбора\n",
        "kernel= ['linear', 'rbf', 'poly', 'sigmoid']\n",
        "C = [.0000001, 1, 100, 1000, 1000000]\n",
        "gamma = [5, 10 , 20, 10]  \n",
        "\n",
        "# kernel= ['linear']\n",
        "# C = [1]\n",
        "# gamma = [5, 10]  \n",
        "\n",
        "# hyperparameter_grid = {'kernel': kernel}\n",
        "# #     'C': C,\n",
        "# #     'gamma': gamma}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAyIMqwKvdFp"
      },
      "source": [
        "### Перебор по сетке с поомщью циклов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsnkL-e3vdFq"
      },
      "source": [
        "# подбор параметрво по сетке\n",
        "\n",
        "acc_score_3 = pd.DataFrame()\n",
        "\n",
        "list_acc_score = []\n",
        "list_kernel = []\n",
        "list_C = []\n",
        "list_gamma= []\n",
        "\n",
        "\n",
        "\n",
        "for kern in kernel :\n",
        "    for c in C :\n",
        "        for gamm in gamma :\n",
        "                \n",
        "                list_kernel.append(kern)\n",
        "                list_C.append(c)\n",
        "                list_gamma.append(gamm)\n",
        "\n",
        "                # define model\n",
        "                model = SVC(decision_function_shape='ovr', kernel = kern, C = c, gamma = gamm)\n",
        "                \n",
        "            \n",
        "                # define the ovr strategy\n",
        "                ovr = OneVsOneClassifier(model)\n",
        "\n",
        "                # fit model\n",
        "                ovr.fit(x_train_split, y_train_split)\n",
        "\n",
        "                # make predictions\n",
        "                y_test_pred = ovr.predict(x_test_split)\n",
        "\n",
        "                # #   проверка качества по кросс валедации\n",
        "                acc = accuracy_score(y_test_pred, y_test_split)\n",
        "\n",
        "                list_acc_score.append(acc)\n",
        "\n",
        "acc_score_3[\"acc_scire\"] = list_acc_score        \n",
        "acc_score_3[\"kernel\"] = list_kernel\n",
        "acc_score_3[\"C\"] = list_C\n",
        "acc_score_3[\"gamma\"] = list_gamma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUn03CVhvdFq"
      },
      "source": [
        "acc_score_3"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}